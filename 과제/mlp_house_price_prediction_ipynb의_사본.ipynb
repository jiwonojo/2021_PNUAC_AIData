{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_house_price_prediction.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w837SI6UaVdr"
      },
      "source": [
        "### 문제정의\n",
        "\n",
        "주택 가격을 예측하는 모델을 만들어보겠습니다. 주택 가격에 영향을 미치는 특성(feature)과 해당 주택의 가격을 지도학습으로 모델에 학습시키서, 임의의 특성을 입력하면, 주택 가격을 예측하는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArC8p6TetDWb"
      },
      "source": [
        "### 데이터셋\n",
        "\n",
        "본 예제에서 사용하는 데이터셋은 케라스에서 제공되는 보스턴 주택 가격 데이터셋을 사용합니다. 상세한 내용은 아래 링크에서 보실 수 있습니다.\n",
        "\n",
        "https://keras.io/api/datasets/boston_housing/\n",
        "\n",
        "특성은 총 13개이며 아래와 같습니다. 범죄율, 방 개수, 세금 등이 보입니다.\n",
        "\n",
        " * CRIM : per capita crime rate by town\n",
        " * ZN : proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        " * INDUS : proportion of non-retail business acres per town\n",
        " * CHAS : Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        " * NOX : nitric oxides concentration (parts per 10 million)\n",
        " * RM : average number of rooms per dwelling\n",
        " * AGE : proportion of owner-occupied units built prior to 1940\n",
        " * DIS : weighted distances to five Boston employment centres\n",
        " * RAD : index of accessibility to radial highways\n",
        " * TAX : full-value property-tax rate per $10,000\n",
        " * PTRATIO : pupil-teacher ratio by town\n",
        " * B : 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        " * LSTAT : % lower status of the population\n",
        " \n",
        "학습시키고자 하는 타겟 인자는 아래와 같습니다. 단위가 1000달러인 주택 가격입니다.\n",
        "\n",
        " * MEDV : Median value of owner-occupied homes in $1000's\n",
        "\n",
        "훈련샘플은 404개이고, 시험샘플은 102개입니다. 데이터셋은 케라스 패키지에서 제공되는 것을 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YkEIljMZ6b0"
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z605__gYbT1Z"
      },
      "source": [
        "데이터셋의 샘플 수와 특성 수를 확인해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hb5gzVPqNwi",
        "outputId": "82479057-52b7-4695-ffcd-091c37f07397"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(404,)\n",
            "(102, 13)\n",
            "(102,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A1JZa2xjD6b"
      },
      "source": [
        "시험셋 샘플 하나를 먼저 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InLDUV9OqWHd",
        "outputId": "0c66ba50-ab44-46cb-c28c-3bab6c356ed5"
      },
      "source": [
        "x_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 18.0846,   0.    ,  18.1   ,   0.    ,   0.679 ,   6.434 ,\n",
              "       100.    ,   1.8347,  24.    , 666.    ,  20.2   ,  27.25  ,\n",
              "        29.05  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_NPDOdbQA3F"
      },
      "source": [
        "머신러닝 모델은 훈련셋을 학습시킨 다음, 추론하는 것이기에 데이터셋에 대한 통계를 확인하는 것이 중요합니다. 훈련셋의 데이터와 라벨를 통합하여 전체 히스토그램을 확인해보겠습니다. 히스토그램은 구간별(x축)로 얼마나 많은 빈도(y축)이 있는 지를 나타낸 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ktdR1ojUsx64",
        "outputId": "e0b9bc48-4ac2-4d46-bb53-f1148019aeb0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_set = np.concatenate((x_train, np.expand_dims(y_train, axis=-1)), axis=1)\n",
        "train_df = pd.DataFrame(train_set)\n",
        "\n",
        "train_df = train_df.rename(columns={0 : 'CRIM',\n",
        "                                    1 : 'ZN',\n",
        "                                    2 : 'INDUS',\n",
        "                                    3 : 'CHAS',\n",
        "                                    4 : 'NOX',\n",
        "                                    5 : 'RM',\n",
        "                                    6 : 'AGE',\n",
        "                                    7 : 'DIS',\n",
        "                                    8 : 'RAD',\n",
        "                                    9 : 'TAX',\n",
        "                                    10 : 'PTRATIO',\n",
        "                                    11 : 'B',\n",
        "                                    12 : 'LSTAT',\n",
        "                                    13 : 'price'})\n",
        "\n",
        "histo = train_df.hist(figsize = [10, 10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM-p2ET-ayXe"
      },
      "source": [
        "### 데이터셋 전처리\n",
        "\n",
        "특성 변수의 값 범위가 특성마다 스케일이 달라서 정규화가 필요합니다. 정규화된 값을 모델에 입력하는 것이 학습 관점에서 유리합니다. 정규화는 평균과 분산을 이용하여 수행합니다. 학습셋에 사용한 정규화 파라미터를 시험셋에도 적용합니다. 추후에 모델을 사용할 때도 학습때 사용된 정규화 파라미터를 사용해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I7ysMuVaAuq"
      },
      "source": [
        "mean = x_train.mean(axis=0)\n",
        "x_train -= mean\n",
        "std = x_train.std(axis=0)\n",
        "x_train /= std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_UYHKSBa32b"
      },
      "source": [
        "### 모델 정의\n",
        "\n",
        "데이터셋 샘플 수가 적어 교차검증을 할 것이기 때문에 모델을 매번 생성하기 쉽게 만들기 위해서 함수로 정의합니다.\n",
        "\n",
        "손실함수는 회귀분석이기 때문에 평균 제곱 오차를 사용하였고, 학습 모니터링에 사용하는 매트릭으로는 평균 절대 오차를 사용했습니다. 평균 절대 오차를 사용하면 직관적으로 오차값을 이해하는 데 용이합니다. \"1\"이면 1000달러만큼 오차가 나는 것이고, \"0.2\"면 200달러만큼 오차가 발생하는 것을 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lbC9RnXaC--"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu', input_shape=(13,)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnpzPTvZbJz9"
      },
      "source": [
        "### 교차검증\n",
        "\n",
        "데이터셋 샘플 수가 비교적 적기 때문에 교차검증을 통해서 모델을 검증합니다. 본 예제에서는 4차 교차검증을 수행합니다. 즉 데이터셋을 4등분해서, 한 그룹을 검증셋으로 두고 나머지 3개 그룹으로 학습시켜서 그 결과를 기록합니다. 이 과정을 검증셋을 바꿔가면서 총 4회를 실행한 후 그 결과를 평균 내서, 검증 수치를 산출합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_LRqlXqaFbm",
        "outputId": "57ee0fe2-2fa5-4966-899c-658814635d29"
      },
      "source": [
        "import numpy as np\n",
        "k = 5\n",
        "num_val_samples = len(x_train) // k\n",
        "num_epochs = 300\n",
        "all_scores = []\n",
        "all_mae_histories = []\n",
        "\n",
        "for i in  range(k):\n",
        "    print(\"processing fold #\", i)\n",
        "\n",
        "    # 검증 데이터 분리\n",
        "    x_val = x_train[i * num_val_samples : (i+1) * num_val_samples]\n",
        "    y_val = y_train[i * num_val_samples : (i+1) * num_val_samples]\n",
        "\n",
        "    # 훈련 데이터 분리\n",
        "    partial_x_train = np.concatenate([x_train[:i*num_val_samples], x_train[(i + 1) * num_val_samples:]], axis=0)\n",
        "    partial_y_train = np.concatenate([y_train[:i*num_val_samples], y_train[(i + 1) * num_val_samples:]], axis=0)\n",
        "\n",
        "    # 모델 학습\n",
        "    model = build_model()\n",
        "    history = model.fit(partial_x_train, partial_y_train, validation_data=(x_val, y_val), epochs=num_epochs, batch_size=20)\n",
        "    \n",
        "    mae_history = history.history['val_mae']\n",
        "    all_mae_histories.append(mae_history)\n",
        "    \n",
        "    val_mse, val_mae = model.evaluate(x_val, y_val, verbose=0)\n",
        "    all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 12s 26ms/step - loss: 608.1061 - mae: 22.6195 - val_loss: 367.1847 - val_mae: 17.1521\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 488.0492 - mae: 19.9144 - val_loss: 267.4764 - val_mae: 14.0961\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 354.1755 - mae: 16.2673 - val_loss: 169.5230 - val_mae: 10.6255\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 196.2044 - mae: 11.7741 - val_loss: 90.3771 - val_mae: 6.9769\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 117.6891 - mae: 8.3451 - val_loss: 53.4559 - val_mae: 5.0479\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 73.6277 - mae: 6.4475 - val_loss: 39.0996 - val_mae: 4.0913\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 54.5324 - mae: 5.2931 - val_loss: 32.3072 - val_mae: 3.6432\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 28.4922 - mae: 4.1122 - val_loss: 27.2918 - val_mae: 3.2974\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 26.3670 - mae: 3.7552 - val_loss: 24.8564 - val_mae: 3.1987\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 27.7496 - mae: 3.6499 - val_loss: 22.7115 - val_mae: 2.9149\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 21.4880 - mae: 3.2034 - val_loss: 20.8919 - val_mae: 2.8043\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 22.0728 - mae: 3.2184 - val_loss: 20.7955 - val_mae: 2.9047\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 23.1044 - mae: 3.2291 - val_loss: 18.2942 - val_mae: 2.7408\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 18.4150 - mae: 2.9421 - val_loss: 17.0929 - val_mae: 2.7363\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 14.3507 - mae: 2.7453 - val_loss: 15.9865 - val_mae: 2.5516\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 17.7212 - mae: 2.9567 - val_loss: 15.4460 - val_mae: 2.5527\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 18.4604 - mae: 2.8313 - val_loss: 14.6759 - val_mae: 2.6616\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 12.9569 - mae: 2.6825 - val_loss: 14.1762 - val_mae: 2.5693\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 13.6788 - mae: 2.5370 - val_loss: 13.2994 - val_mae: 2.2788\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 16.5452 - mae: 2.7106 - val_loss: 12.4166 - val_mae: 2.2483\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 11.8032 - mae: 2.4654 - val_loss: 11.9671 - val_mae: 2.2853\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 14.2952 - mae: 2.6354 - val_loss: 12.5184 - val_mae: 2.3379\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 12.8330 - mae: 2.5120 - val_loss: 10.9914 - val_mae: 2.1550\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 13.4551 - mae: 2.6241 - val_loss: 10.7179 - val_mae: 2.1354\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 15.8610 - mae: 2.5994 - val_loss: 11.5737 - val_mae: 2.2312\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.2058 - mae: 2.2456 - val_loss: 10.0716 - val_mae: 2.0841\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 10.4380 - mae: 2.4076 - val_loss: 10.1715 - val_mae: 2.0405\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 9.4227 - mae: 2.2638 - val_loss: 9.4631 - val_mae: 2.0063\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.7471 - mae: 2.2945 - val_loss: 10.7372 - val_mae: 2.3062\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 12.1207 - mae: 2.4257 - val_loss: 9.5977 - val_mae: 2.0421\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 11.8192 - mae: 2.3577 - val_loss: 9.0348 - val_mae: 1.9325\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 11.3602 - mae: 2.3692 - val_loss: 9.4571 - val_mae: 2.0173\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 11.2552 - mae: 2.3504 - val_loss: 8.8591 - val_mae: 1.9269\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.6082 - mae: 2.2854 - val_loss: 9.0717 - val_mae: 1.9649\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.5678 - mae: 2.3804 - val_loss: 8.4144 - val_mae: 1.8909\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.2849 - mae: 2.2934 - val_loss: 8.7591 - val_mae: 1.9973\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 9.9532 - mae: 2.2473 - val_loss: 8.8661 - val_mae: 2.0318\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.7199 - mae: 2.2024 - val_loss: 8.2682 - val_mae: 1.9614\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.7912 - mae: 2.0054 - val_loss: 8.5429 - val_mae: 1.8856\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.4124 - mae: 2.0736 - val_loss: 7.9069 - val_mae: 1.8877\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.6626 - mae: 2.2179 - val_loss: 8.3779 - val_mae: 1.9329\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.9428 - mae: 2.2722 - val_loss: 8.3816 - val_mae: 1.8166\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.3617 - mae: 2.0919 - val_loss: 8.1207 - val_mae: 1.9225\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.5808 - mae: 1.9560 - val_loss: 7.9595 - val_mae: 1.9205\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 10.5085 - mae: 2.2311 - val_loss: 7.7307 - val_mae: 1.8410\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.3255 - mae: 2.1519 - val_loss: 7.7022 - val_mae: 1.8275\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.5591 - mae: 2.1482 - val_loss: 8.1855 - val_mae: 1.8724\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 9.6234 - mae: 2.1567 - val_loss: 7.5785 - val_mae: 1.7836\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 10.5296 - mae: 2.2019 - val_loss: 7.8618 - val_mae: 1.8071\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.9202 - mae: 2.0847 - val_loss: 7.7998 - val_mae: 1.8687\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.5367 - mae: 2.0095 - val_loss: 7.6070 - val_mae: 1.8963\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.4288 - mae: 2.0708 - val_loss: 7.5333 - val_mae: 1.8256\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.8449 - mae: 2.1522 - val_loss: 7.5293 - val_mae: 1.8048\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.1284 - mae: 1.9469 - val_loss: 7.7536 - val_mae: 1.9284\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 11.0250 - mae: 2.1467 - val_loss: 7.7045 - val_mae: 1.8036\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.5442 - mae: 2.0107 - val_loss: 7.7091 - val_mae: 1.9628\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.1411 - mae: 1.9551 - val_loss: 8.0951 - val_mae: 2.0745\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.3292 - mae: 2.0657 - val_loss: 7.8278 - val_mae: 1.8304\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.5478 - mae: 1.9929 - val_loss: 7.5041 - val_mae: 1.8830\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.1562 - mae: 1.9451 - val_loss: 7.3118 - val_mae: 1.7688\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.6321 - mae: 1.8588 - val_loss: 7.7343 - val_mae: 1.7806\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 10.7772 - mae: 2.1169 - val_loss: 7.3698 - val_mae: 1.8085\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.0998 - mae: 1.9999 - val_loss: 7.3096 - val_mae: 1.7651\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.3485 - mae: 1.9874 - val_loss: 6.9657 - val_mae: 1.8037\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.6810 - mae: 1.9512 - val_loss: 7.0797 - val_mae: 1.8030\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.8724 - mae: 1.8612 - val_loss: 7.0130 - val_mae: 1.7214\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.5319 - mae: 1.8689 - val_loss: 7.1071 - val_mae: 1.7289\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.5380 - mae: 1.9500 - val_loss: 7.0517 - val_mae: 1.7059\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.4392 - mae: 1.9014 - val_loss: 6.6380 - val_mae: 1.7856\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.2243 - mae: 1.8959 - val_loss: 6.7012 - val_mae: 1.7223\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.1076 - mae: 1.9902 - val_loss: 6.6387 - val_mae: 1.7328\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.4128 - mae: 1.7551 - val_loss: 6.7327 - val_mae: 1.7284\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.8981 - mae: 1.8218 - val_loss: 6.7022 - val_mae: 1.7968\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 9.0657 - mae: 1.9149 - val_loss: 7.3091 - val_mae: 1.7948\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.4234 - mae: 1.8587 - val_loss: 7.8030 - val_mae: 1.8270\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 9.3845 - mae: 1.9535 - val_loss: 6.6586 - val_mae: 1.7811\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.2259 - mae: 1.8936 - val_loss: 7.0042 - val_mae: 1.8261\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.5470 - mae: 1.8796 - val_loss: 7.1290 - val_mae: 1.7861\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.4514 - mae: 1.9204 - val_loss: 7.5325 - val_mae: 1.8219\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.7457 - mae: 1.8070 - val_loss: 7.3971 - val_mae: 1.7605\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.7595 - mae: 1.8059 - val_loss: 7.4109 - val_mae: 2.0718\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.7794 - mae: 1.9766 - val_loss: 6.9043 - val_mae: 1.8588\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.5625 - mae: 2.0455 - val_loss: 6.7369 - val_mae: 1.7165\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.4188 - mae: 1.8335 - val_loss: 6.8323 - val_mae: 1.7138\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.1272 - mae: 1.8050 - val_loss: 7.1382 - val_mae: 1.8625\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.4394 - mae: 1.8160 - val_loss: 6.5675 - val_mae: 1.8762\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.9398 - mae: 1.8619 - val_loss: 7.3777 - val_mae: 2.1121\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.7068 - mae: 1.9328 - val_loss: 6.6729 - val_mae: 1.7412\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.2506 - mae: 2.0804 - val_loss: 7.0377 - val_mae: 1.9780\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.6010 - mae: 1.8585 - val_loss: 6.8744 - val_mae: 1.9833\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.2743 - mae: 1.9079 - val_loss: 6.3260 - val_mae: 1.7276\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.3531 - mae: 1.8457 - val_loss: 6.7129 - val_mae: 1.7380\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.9928 - mae: 1.6883 - val_loss: 6.6353 - val_mae: 1.9014\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.2983 - mae: 1.9009 - val_loss: 6.4262 - val_mae: 1.7791\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.6798 - mae: 1.8836 - val_loss: 6.2210 - val_mae: 1.7502\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.1890 - mae: 1.6218 - val_loss: 6.5592 - val_mae: 1.9354\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.2339 - mae: 1.8813 - val_loss: 6.8737 - val_mae: 1.8062\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.8925 - mae: 1.8599 - val_loss: 6.6738 - val_mae: 1.9361\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.6644 - mae: 1.8216 - val_loss: 6.4841 - val_mae: 1.9153\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.9204 - mae: 1.8208 - val_loss: 6.4861 - val_mae: 1.7786\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.9144 - mae: 1.7935 - val_loss: 6.4503 - val_mae: 1.7231\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.6377 - mae: 1.7340 - val_loss: 7.5460 - val_mae: 2.1904\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.9719 - mae: 1.9619 - val_loss: 6.3963 - val_mae: 1.7345\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.0125 - mae: 1.7791 - val_loss: 6.4132 - val_mae: 1.7732\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.6799 - mae: 1.8331 - val_loss: 6.2215 - val_mae: 1.7717\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.6940 - mae: 1.8457 - val_loss: 7.6697 - val_mae: 2.0105\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.3757 - mae: 1.8201 - val_loss: 6.2636 - val_mae: 1.7816\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.2138 - mae: 1.8364 - val_loss: 6.3499 - val_mae: 1.8316\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.6246 - mae: 1.6999 - val_loss: 6.8085 - val_mae: 1.9556\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.9353 - mae: 1.8769 - val_loss: 6.4807 - val_mae: 1.8503\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.8095 - mae: 1.6677 - val_loss: 6.5234 - val_mae: 1.7394\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.6763 - mae: 1.7592 - val_loss: 6.8712 - val_mae: 2.0193\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.3094 - mae: 1.6353 - val_loss: 6.2781 - val_mae: 1.8114\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.7826 - mae: 1.7607 - val_loss: 6.1822 - val_mae: 1.7813\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.4751 - mae: 1.5458 - val_loss: 6.2577 - val_mae: 1.8515\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.3655 - mae: 1.7778 - val_loss: 6.2493 - val_mae: 1.7563\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.7565 - mae: 1.7286 - val_loss: 6.1914 - val_mae: 1.8137\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.3823 - mae: 1.6943 - val_loss: 6.2563 - val_mae: 1.8054\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.9116 - mae: 1.6365 - val_loss: 7.3159 - val_mae: 1.8304\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.2305 - mae: 1.8514 - val_loss: 6.3219 - val_mae: 1.7929\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.7771 - mae: 1.8283 - val_loss: 6.2505 - val_mae: 1.7936\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.7257 - mae: 1.8363 - val_loss: 6.5952 - val_mae: 1.7260\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.5296 - mae: 1.7069 - val_loss: 7.3042 - val_mae: 1.9647\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0899 - mae: 1.5913 - val_loss: 6.2170 - val_mae: 1.8624\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.7433 - mae: 1.8492 - val_loss: 6.3657 - val_mae: 1.7483\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.5781 - mae: 1.7054 - val_loss: 6.1967 - val_mae: 1.8707\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.0628 - mae: 1.7623 - val_loss: 6.0220 - val_mae: 1.8471\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.1489 - mae: 1.6989 - val_loss: 6.0121 - val_mae: 1.7775\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.8624 - mae: 1.6133 - val_loss: 5.9705 - val_mae: 1.8279\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.7637 - mae: 1.6522 - val_loss: 6.0020 - val_mae: 1.7509\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.6852 - mae: 1.6596 - val_loss: 6.4501 - val_mae: 1.7275\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.2514 - mae: 1.7729 - val_loss: 5.9852 - val_mae: 1.8056\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.1537 - mae: 1.7076 - val_loss: 6.5678 - val_mae: 1.8499\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.1424 - mae: 1.7822 - val_loss: 6.2065 - val_mae: 1.7893\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.3058 - mae: 1.6079 - val_loss: 6.1939 - val_mae: 1.8590\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.6044 - mae: 1.5869 - val_loss: 6.3727 - val_mae: 1.7874\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.2625 - mae: 1.6306 - val_loss: 7.0920 - val_mae: 1.7966\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.2678 - mae: 1.6188 - val_loss: 6.1533 - val_mae: 1.9105\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.0578 - mae: 1.6267 - val_loss: 6.3581 - val_mae: 1.7927\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.4853 - mae: 1.6495 - val_loss: 7.0744 - val_mae: 1.7927\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.1816 - mae: 1.5983 - val_loss: 6.8953 - val_mae: 1.8296\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.4035 - mae: 1.6657 - val_loss: 6.6454 - val_mae: 1.7480\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.0223 - mae: 1.8257 - val_loss: 5.9184 - val_mae: 1.8232\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.6574 - mae: 1.6390 - val_loss: 6.4163 - val_mae: 1.8700\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.5496 - mae: 1.5892 - val_loss: 5.8099 - val_mae: 1.7379\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.2658 - mae: 1.5983 - val_loss: 5.8759 - val_mae: 1.7374\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.1344 - mae: 1.5085 - val_loss: 6.2126 - val_mae: 1.7812\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.5686 - mae: 1.7790 - val_loss: 6.5631 - val_mae: 1.7604\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.6913 - mae: 1.5521 - val_loss: 6.2212 - val_mae: 1.7385\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1300 - mae: 1.5918 - val_loss: 6.0661 - val_mae: 1.7476\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.4056 - mae: 1.6716 - val_loss: 6.2273 - val_mae: 1.8876\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1282 - mae: 1.4593 - val_loss: 6.5633 - val_mae: 2.0614\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8143 - mae: 1.5413 - val_loss: 5.9735 - val_mae: 1.8571\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1278 - mae: 1.6252 - val_loss: 6.3560 - val_mae: 1.7645\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.9108 - mae: 1.5219 - val_loss: 6.1359 - val_mae: 1.8600\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.5956 - mae: 1.7022 - val_loss: 6.8703 - val_mae: 1.8338\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.2037 - mae: 1.6059 - val_loss: 5.8683 - val_mae: 1.7989\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.1370 - mae: 1.5264 - val_loss: 5.9411 - val_mae: 1.7652\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9960 - mae: 1.4315 - val_loss: 6.2254 - val_mae: 1.8441\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2898 - mae: 1.5045 - val_loss: 6.3978 - val_mae: 1.9824\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.6871 - mae: 1.6017 - val_loss: 7.0516 - val_mae: 2.0922\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.2303 - mae: 1.4942 - val_loss: 7.3572 - val_mae: 1.9273\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.6975 - mae: 1.6667 - val_loss: 5.9546 - val_mae: 1.7962\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.9530 - mae: 1.5850 - val_loss: 6.0707 - val_mae: 1.7571\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.8440 - mae: 1.5365 - val_loss: 6.5244 - val_mae: 1.8931\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.0470 - mae: 1.6530 - val_loss: 6.3550 - val_mae: 1.7741\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.4407 - mae: 1.5866 - val_loss: 6.2627 - val_mae: 1.8582\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.1332 - mae: 1.4578 - val_loss: 7.3398 - val_mae: 2.1916\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8889 - mae: 1.5883 - val_loss: 6.2112 - val_mae: 1.9047\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1819 - mae: 1.4321 - val_loss: 6.4142 - val_mae: 2.0016\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0416 - mae: 1.5955 - val_loss: 7.9224 - val_mae: 2.0758\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.4246 - mae: 1.5892 - val_loss: 6.3883 - val_mae: 1.7997\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.3266 - mae: 1.4791 - val_loss: 7.0596 - val_mae: 1.9242\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.9434 - mae: 1.5966 - val_loss: 7.0841 - val_mae: 2.1106\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.1567 - mae: 1.4750 - val_loss: 6.5054 - val_mae: 2.0483\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3015 - mae: 1.4819 - val_loss: 6.1037 - val_mae: 1.8104\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.1878 - mae: 1.5547 - val_loss: 6.0837 - val_mae: 1.8982\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0220 - mae: 1.4754 - val_loss: 7.1102 - val_mae: 1.9499\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.4732 - mae: 1.5845 - val_loss: 6.7932 - val_mae: 1.9453\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.2273 - mae: 1.5499 - val_loss: 6.2378 - val_mae: 1.8766\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.5064 - mae: 1.4568 - val_loss: 7.0527 - val_mae: 1.9282\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.2375 - mae: 1.6025 - val_loss: 6.1235 - val_mae: 1.9053\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.0649 - mae: 1.3926 - val_loss: 6.2040 - val_mae: 1.7903\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.6194 - mae: 1.4628 - val_loss: 6.3344 - val_mae: 1.9395\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.4074 - mae: 1.5547 - val_loss: 6.6048 - val_mae: 1.8701\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.2008 - mae: 1.4259 - val_loss: 6.1130 - val_mae: 1.8838\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.4703 - mae: 1.3426 - val_loss: 7.5111 - val_mae: 2.2208\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.1182 - mae: 1.4298 - val_loss: 6.5475 - val_mae: 1.8966\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5120 - mae: 1.3599 - val_loss: 6.2094 - val_mae: 1.8604\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.4470 - mae: 1.4494 - val_loss: 7.3325 - val_mae: 2.0888\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.9255 - mae: 1.5538 - val_loss: 6.3123 - val_mae: 1.9217\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.6624 - mae: 1.2927 - val_loss: 6.5223 - val_mae: 1.8534\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8196 - mae: 1.4176 - val_loss: 6.6909 - val_mae: 1.8556\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.2695 - mae: 1.5333 - val_loss: 6.5691 - val_mae: 1.9429\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.6937 - mae: 1.4879 - val_loss: 6.5376 - val_mae: 1.8993\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.6976 - mae: 1.4412 - val_loss: 7.1795 - val_mae: 1.9177\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1573 - mae: 1.4820 - val_loss: 6.9934 - val_mae: 2.0123\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.8982 - mae: 1.4115 - val_loss: 6.2842 - val_mae: 1.9188\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2956 - mae: 1.4505 - val_loss: 6.9896 - val_mae: 2.1687\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.4070 - mae: 1.3747 - val_loss: 7.0624 - val_mae: 2.1619\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.5147 - mae: 1.6104 - val_loss: 6.4524 - val_mae: 1.8309\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0864 - mae: 1.3152 - val_loss: 7.2235 - val_mae: 2.2397\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3415 - mae: 1.4361 - val_loss: 6.6630 - val_mae: 1.9060\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.8661 - mae: 1.3875 - val_loss: 7.1775 - val_mae: 2.1064\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9345 - mae: 1.4561 - val_loss: 7.6457 - val_mae: 2.0265\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2848 - mae: 1.4611 - val_loss: 6.4222 - val_mae: 1.8713\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8613 - mae: 1.3381 - val_loss: 6.4017 - val_mae: 1.9678\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.6658 - mae: 1.4332 - val_loss: 6.0981 - val_mae: 1.8483\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9908 - mae: 1.3511 - val_loss: 6.3390 - val_mae: 1.8868\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 5.2140 - mae: 1.4809 - val_loss: 6.7001 - val_mae: 1.9175\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.5591 - mae: 1.3151 - val_loss: 6.3678 - val_mae: 1.8962\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.4069 - mae: 1.3221 - val_loss: 7.5387 - val_mae: 2.2780\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1733 - mae: 1.4864 - val_loss: 7.4434 - val_mae: 1.9764\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.0963 - mae: 1.3052 - val_loss: 6.6923 - val_mae: 1.9979\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.6710 - mae: 1.3701 - val_loss: 7.0772 - val_mae: 2.1698\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.9125 - mae: 1.4862 - val_loss: 6.9026 - val_mae: 2.0275\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7641 - mae: 1.3645 - val_loss: 6.9418 - val_mae: 1.9754\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4523 - mae: 1.2669 - val_loss: 6.9092 - val_mae: 1.9092\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.4093 - mae: 1.4278 - val_loss: 6.6682 - val_mae: 1.8681\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3980 - mae: 1.3109 - val_loss: 7.0476 - val_mae: 1.9977\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3053 - mae: 1.2793 - val_loss: 6.4034 - val_mae: 1.9213\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7393 - mae: 1.3220 - val_loss: 6.7356 - val_mae: 2.0467\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.7302 - mae: 1.3593 - val_loss: 6.7170 - val_mae: 2.0655\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8957 - mae: 1.2331 - val_loss: 6.7958 - val_mae: 2.1103\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0160 - mae: 1.2594 - val_loss: 6.8676 - val_mae: 2.0210\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2883 - mae: 1.3456 - val_loss: 6.9635 - val_mae: 1.9289\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7908 - mae: 1.3501 - val_loss: 7.1030 - val_mae: 2.1494\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.8669 - mae: 1.4512 - val_loss: 7.8044 - val_mae: 2.2396\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8177 - mae: 1.4631 - val_loss: 10.8244 - val_mae: 2.6480\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.4225 - mae: 1.5319 - val_loss: 6.6962 - val_mae: 1.9073\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.4249 - mae: 1.2904 - val_loss: 6.4953 - val_mae: 2.0061\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0428 - mae: 1.3311 - val_loss: 7.2711 - val_mae: 2.2201\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6645 - mae: 1.3730 - val_loss: 7.1872 - val_mae: 2.1559\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.8887 - mae: 1.3456 - val_loss: 7.0967 - val_mae: 1.9464\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9278 - mae: 1.2406 - val_loss: 8.2077 - val_mae: 2.2472\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0162 - mae: 1.4388 - val_loss: 7.7064 - val_mae: 2.0834\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7900 - mae: 1.1908 - val_loss: 7.4808 - val_mae: 1.9793\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.5128 - mae: 1.2596 - val_loss: 7.0502 - val_mae: 2.0635\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6395 - mae: 1.1835 - val_loss: 7.3394 - val_mae: 1.9883\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9260 - mae: 1.3647 - val_loss: 6.8508 - val_mae: 2.0739\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.9254 - mae: 1.2450 - val_loss: 7.7320 - val_mae: 2.2623\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1437 - mae: 1.4118 - val_loss: 8.3096 - val_mae: 2.3206\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2248 - mae: 1.4268 - val_loss: 6.8906 - val_mae: 2.0479\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2722 - mae: 1.2370 - val_loss: 7.0471 - val_mae: 1.9366\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2214 - mae: 1.2651 - val_loss: 7.6982 - val_mae: 2.0501\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.1643 - mae: 1.2399 - val_loss: 7.8087 - val_mae: 2.0577\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3939 - mae: 1.3111 - val_loss: 8.2650 - val_mae: 2.2119\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6303 - mae: 1.3594 - val_loss: 7.0895 - val_mae: 2.0354\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.1805 - mae: 1.2915 - val_loss: 7.9013 - val_mae: 2.0402\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8454 - mae: 1.3707 - val_loss: 7.1525 - val_mae: 2.1649\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8303 - mae: 1.4192 - val_loss: 7.4270 - val_mae: 2.1001\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9810 - mae: 1.2105 - val_loss: 8.1068 - val_mae: 2.2026\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5214 - mae: 1.3559 - val_loss: 7.4157 - val_mae: 2.0902\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.5617 - mae: 1.3256 - val_loss: 6.9884 - val_mae: 1.9324\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.1814 - mae: 1.2511 - val_loss: 7.6225 - val_mae: 2.0763\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.4403 - mae: 1.3147 - val_loss: 8.2001 - val_mae: 2.2713\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.4088 - mae: 1.2564 - val_loss: 7.9213 - val_mae: 2.3321\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4263 - mae: 1.3636 - val_loss: 7.1271 - val_mae: 2.0615\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.1594 - mae: 1.2853 - val_loss: 7.2827 - val_mae: 2.0006\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7941 - mae: 1.1137 - val_loss: 8.1505 - val_mae: 2.1667\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0821 - mae: 1.2321 - val_loss: 7.3502 - val_mae: 2.1709\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6000 - mae: 1.1874 - val_loss: 7.1471 - val_mae: 2.0891\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6845 - mae: 1.1569 - val_loss: 8.6708 - val_mae: 2.1812\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8516 - mae: 1.3312 - val_loss: 8.4838 - val_mae: 2.4399\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.2779 - mae: 1.3257 - val_loss: 7.2496 - val_mae: 1.9768\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7011 - mae: 1.1658 - val_loss: 7.1674 - val_mae: 1.9765\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.4081 - mae: 1.4080 - val_loss: 7.3290 - val_mae: 2.2011\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.1100 - mae: 1.2293 - val_loss: 8.9878 - val_mae: 2.2880\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.1678 - mae: 1.2732 - val_loss: 7.5637 - val_mae: 2.1814\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6705 - mae: 1.3646 - val_loss: 7.6811 - val_mae: 2.2787\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8997 - mae: 1.2820 - val_loss: 8.1090 - val_mae: 2.1396\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4663 - mae: 1.1207 - val_loss: 7.2227 - val_mae: 2.0431\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.5106 - mae: 1.2587 - val_loss: 7.7231 - val_mae: 2.0718\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3142 - mae: 1.2991 - val_loss: 6.9710 - val_mae: 2.0216\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4689 - mae: 1.0992 - val_loss: 7.4904 - val_mae: 2.0045\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0417 - mae: 1.1598 - val_loss: 8.1847 - val_mae: 2.1065\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5141 - mae: 1.3207 - val_loss: 7.2216 - val_mae: 2.0837\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4095 - mae: 1.0820 - val_loss: 7.2084 - val_mae: 2.0228\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.7499 - mae: 1.1754 - val_loss: 7.3540 - val_mae: 2.0389\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2653 - mae: 1.1035 - val_loss: 7.4854 - val_mae: 2.0955\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7591 - mae: 1.1259 - val_loss: 7.9575 - val_mae: 2.3071\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3663 - mae: 1.3181 - val_loss: 7.4450 - val_mae: 2.0887\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7235 - mae: 1.1773 - val_loss: 8.0703 - val_mae: 2.1101\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2070 - mae: 1.2152 - val_loss: 7.2083 - val_mae: 2.1500\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7929 - mae: 1.1804 - val_loss: 7.5549 - val_mae: 2.0457\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8112 - mae: 1.1634 - val_loss: 7.1718 - val_mae: 2.0101\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5649 - mae: 1.1654 - val_loss: 7.3388 - val_mae: 2.0236\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9111 - mae: 1.2269 - val_loss: 8.4806 - val_mae: 2.2373\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.5438 - mae: 1.1757 - val_loss: 8.1591 - val_mae: 2.1224\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.5325 - mae: 1.2087 - val_loss: 7.5717 - val_mae: 2.1097\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.8236 - mae: 1.2036 - val_loss: 7.9658 - val_mae: 2.0856\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.6403 - mae: 1.1977 - val_loss: 8.8167 - val_mae: 2.2169\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8832 - mae: 1.2449 - val_loss: 8.0069 - val_mae: 2.1688\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7952 - mae: 1.1547 - val_loss: 7.0373 - val_mae: 2.0012\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4451 - mae: 1.1039 - val_loss: 7.9418 - val_mae: 2.1045\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5708 - mae: 1.1437 - val_loss: 7.4487 - val_mae: 2.0484\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2388 - mae: 1.0703 - val_loss: 8.1880 - val_mae: 2.2156\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0546 - mae: 1.2181 - val_loss: 7.8254 - val_mae: 2.0733\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.3539 - mae: 1.1036 - val_loss: 8.3262 - val_mae: 2.1546\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.0431 - mae: 1.1774 - val_loss: 8.3704 - val_mae: 2.1018\n",
            "processing fold # 1\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 15ms/step - loss: 509.6867 - mae: 20.7676 - val_loss: 480.4517 - val_mae: 19.7014\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 355.3361 - mae: 16.9955 - val_loss: 323.7197 - val_mae: 15.8793\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 247.3091 - mae: 13.5087 - val_loss: 193.7589 - val_mae: 11.7727\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 161.9610 - mae: 10.2161 - val_loss: 101.6355 - val_mae: 8.1396\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 86.6753 - mae: 7.4786 - val_loss: 60.2796 - val_mae: 6.2799\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 56.8396 - mae: 5.8913 - val_loss: 40.7636 - val_mae: 5.1236\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 50.3210 - mae: 5.1162 - val_loss: 31.4598 - val_mae: 4.4317\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 33.0107 - mae: 4.2172 - val_loss: 24.9967 - val_mae: 3.8792\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 25.9739 - mae: 3.7716 - val_loss: 23.1138 - val_mae: 3.8682\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 30.1440 - mae: 3.8214 - val_loss: 22.1660 - val_mae: 3.7191\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 20.8787 - mae: 3.2951 - val_loss: 22.2741 - val_mae: 3.7797\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 25.8839 - mae: 3.4743 - val_loss: 21.5227 - val_mae: 3.6338\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 19.2577 - mae: 2.8749 - val_loss: 20.4381 - val_mae: 3.5532\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 18.5993 - mae: 3.0190 - val_loss: 18.8419 - val_mae: 3.4108\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 16.9622 - mae: 2.8469 - val_loss: 18.4007 - val_mae: 3.4018\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 19.0985 - mae: 2.8847 - val_loss: 17.0423 - val_mae: 3.2424\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 17.5297 - mae: 2.8325 - val_loss: 16.3602 - val_mae: 3.1822\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 14.8243 - mae: 2.6271 - val_loss: 14.9129 - val_mae: 3.0528\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 15.2496 - mae: 2.6673 - val_loss: 17.1395 - val_mae: 3.2055\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 13.7495 - mae: 2.5978 - val_loss: 16.0178 - val_mae: 3.0989\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 12.1271 - mae: 2.3866 - val_loss: 15.0762 - val_mae: 3.0279\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 12.6305 - mae: 2.4499 - val_loss: 13.4049 - val_mae: 2.8772\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 11.2727 - mae: 2.3447 - val_loss: 15.1866 - val_mae: 3.0001\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 9.3159 - mae: 2.1928 - val_loss: 14.6737 - val_mae: 2.9435\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 11.1517 - mae: 2.3714 - val_loss: 13.4416 - val_mae: 2.8361\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.9474 - mae: 2.3380 - val_loss: 13.9812 - val_mae: 2.8499\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 13.1352 - mae: 2.5272 - val_loss: 14.6486 - val_mae: 2.9296\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.8055 - mae: 2.3799 - val_loss: 13.8081 - val_mae: 2.8245\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.2584 - mae: 2.2431 - val_loss: 13.1454 - val_mae: 2.7776\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.7413 - mae: 2.0399 - val_loss: 15.1494 - val_mae: 2.9755\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.6137 - mae: 2.1481 - val_loss: 13.8038 - val_mae: 2.8173\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.9763 - mae: 2.1029 - val_loss: 14.5049 - val_mae: 2.8843\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.5979 - mae: 2.2752 - val_loss: 15.7588 - val_mae: 3.0161\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 9.1178 - mae: 2.2133 - val_loss: 13.4843 - val_mae: 2.8128\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.0728 - mae: 2.0819 - val_loss: 14.8691 - val_mae: 2.9243\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.9134 - mae: 2.0644 - val_loss: 13.6628 - val_mae: 2.8085\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 9.3895 - mae: 2.1902 - val_loss: 14.2294 - val_mae: 2.8513\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 9.0557 - mae: 2.2217 - val_loss: 12.4446 - val_mae: 2.7367\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.7635 - mae: 2.1917 - val_loss: 13.6838 - val_mae: 2.8362\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.5393 - mae: 2.0477 - val_loss: 13.9867 - val_mae: 2.8593\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.2077 - mae: 2.0929 - val_loss: 13.5259 - val_mae: 2.7741\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.4512 - mae: 2.0204 - val_loss: 13.8975 - val_mae: 2.7938\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.6333 - mae: 2.0875 - val_loss: 13.5469 - val_mae: 2.7938\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.8159 - mae: 1.9349 - val_loss: 13.8761 - val_mae: 2.8143\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.2751 - mae: 1.9632 - val_loss: 13.1454 - val_mae: 2.7524\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.1705 - mae: 1.9210 - val_loss: 14.9048 - val_mae: 2.9430\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.1259 - mae: 2.0951 - val_loss: 13.2218 - val_mae: 2.7438\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.7296 - mae: 2.0350 - val_loss: 13.0804 - val_mae: 2.7296\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.3283 - mae: 2.0260 - val_loss: 14.1280 - val_mae: 2.8396\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.9254 - mae: 1.8321 - val_loss: 15.1611 - val_mae: 2.9421\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 7.6478 - mae: 1.9556 - val_loss: 12.9050 - val_mae: 2.7206\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 8.5204 - mae: 2.0323 - val_loss: 13.6378 - val_mae: 2.8010\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.3606 - mae: 1.7958 - val_loss: 12.8792 - val_mae: 2.7083\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.0873 - mae: 1.8943 - val_loss: 12.9425 - val_mae: 2.7244\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.7271 - mae: 2.1026 - val_loss: 13.3334 - val_mae: 2.7668\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.0561 - mae: 2.0286 - val_loss: 13.9116 - val_mae: 2.8044\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.5735 - mae: 1.8600 - val_loss: 14.5716 - val_mae: 2.8724\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.1355 - mae: 2.0384 - val_loss: 16.3054 - val_mae: 3.0452\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.5356 - mae: 1.8878 - val_loss: 13.3826 - val_mae: 2.7538\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.1663 - mae: 2.0648 - val_loss: 13.2113 - val_mae: 2.7300\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.0232 - mae: 1.9740 - val_loss: 15.2431 - val_mae: 2.9233\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.8374 - mae: 1.9372 - val_loss: 12.9859 - val_mae: 2.7244\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.7000 - mae: 1.7713 - val_loss: 14.3702 - val_mae: 2.8566\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.5350 - mae: 1.9714 - val_loss: 12.9321 - val_mae: 2.7271\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7418 - mae: 1.8619 - val_loss: 13.7575 - val_mae: 2.8073\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 6.6311 - mae: 1.8158 - val_loss: 15.4209 - val_mae: 3.0016\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7157 - mae: 1.8010 - val_loss: 13.2160 - val_mae: 2.7541\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.1682 - mae: 1.8975 - val_loss: 13.6445 - val_mae: 2.7909\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.9965 - mae: 1.7738 - val_loss: 13.4576 - val_mae: 2.7535\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.0816 - mae: 1.8566 - val_loss: 14.8492 - val_mae: 2.8893\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.3677 - mae: 1.7985 - val_loss: 12.7828 - val_mae: 2.7170\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0728 - mae: 1.6732 - val_loss: 13.7312 - val_mae: 2.7948\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.6724 - mae: 1.7875 - val_loss: 14.6825 - val_mae: 2.9023\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.1279 - mae: 1.7667 - val_loss: 13.8553 - val_mae: 2.8384\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.0996 - mae: 1.9202 - val_loss: 14.4746 - val_mae: 2.8249\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.3362 - mae: 1.9014 - val_loss: 13.8395 - val_mae: 2.8196\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.5681 - mae: 1.7686 - val_loss: 12.9177 - val_mae: 2.7056\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.9678 - mae: 1.9007 - val_loss: 13.2225 - val_mae: 2.7313\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.3277 - mae: 1.5891 - val_loss: 15.4875 - val_mae: 2.9567\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1725 - mae: 1.6757 - val_loss: 14.3436 - val_mae: 2.8010\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.9416 - mae: 1.6456 - val_loss: 15.2073 - val_mae: 2.8841\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0755 - mae: 1.6702 - val_loss: 14.0942 - val_mae: 2.8290\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.5464 - mae: 1.7892 - val_loss: 14.7312 - val_mae: 2.9092\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.4603 - mae: 1.6983 - val_loss: 13.6722 - val_mae: 2.7661\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.6456 - mae: 1.5747 - val_loss: 14.5446 - val_mae: 2.8537\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.6456 - mae: 1.5737 - val_loss: 12.8708 - val_mae: 2.7139\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8366 - mae: 1.5796 - val_loss: 15.1509 - val_mae: 2.9126\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7671 - mae: 1.5941 - val_loss: 14.5277 - val_mae: 2.8379\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0091 - mae: 1.6404 - val_loss: 13.5463 - val_mae: 2.7494\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.6177 - mae: 1.5489 - val_loss: 13.9607 - val_mae: 2.7710\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0200 - mae: 1.6194 - val_loss: 13.0583 - val_mae: 2.7445\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.8467 - mae: 1.5818 - val_loss: 15.2343 - val_mae: 2.9056\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.1644 - mae: 1.7535 - val_loss: 13.4613 - val_mae: 2.7494\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.2066 - mae: 1.7348 - val_loss: 14.4103 - val_mae: 2.8048\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.7061 - mae: 1.5586 - val_loss: 13.9845 - val_mae: 2.7971\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.5708 - mae: 1.5038 - val_loss: 15.8550 - val_mae: 2.9650\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.8412 - mae: 1.6718 - val_loss: 14.2634 - val_mae: 2.8389\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.1893 - mae: 1.6441 - val_loss: 14.2066 - val_mae: 2.8287\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7027 - mae: 1.8075 - val_loss: 13.2334 - val_mae: 2.7510\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.3538 - mae: 1.7259 - val_loss: 12.1513 - val_mae: 2.6342\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2951 - mae: 1.5135 - val_loss: 17.3275 - val_mae: 3.0493\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1812 - mae: 1.6188 - val_loss: 13.3614 - val_mae: 2.7103\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8744 - mae: 1.4973 - val_loss: 11.9446 - val_mae: 2.6323\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.9448 - mae: 1.7048 - val_loss: 12.6671 - val_mae: 2.6529\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2504 - mae: 1.4508 - val_loss: 12.7889 - val_mae: 2.6618\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.4900 - mae: 1.5188 - val_loss: 15.4525 - val_mae: 2.9223\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.6073 - mae: 1.5604 - val_loss: 12.7515 - val_mae: 2.6380\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1888 - mae: 1.4064 - val_loss: 13.3759 - val_mae: 2.7176\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1426 - mae: 1.4875 - val_loss: 12.8363 - val_mae: 2.7091\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0835 - mae: 1.4590 - val_loss: 16.2715 - val_mae: 2.9896\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.6682 - mae: 1.5396 - val_loss: 12.3449 - val_mae: 2.6057\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7458 - mae: 1.5193 - val_loss: 14.3062 - val_mae: 2.7594\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.9208 - mae: 1.6802 - val_loss: 14.2835 - val_mae: 2.8698\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3686 - mae: 1.4876 - val_loss: 12.8459 - val_mae: 2.6750\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.5023 - mae: 1.5147 - val_loss: 13.3102 - val_mae: 2.6776\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8446 - mae: 1.3963 - val_loss: 13.8326 - val_mae: 2.7012\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2363 - mae: 1.3162 - val_loss: 15.8824 - val_mae: 2.9268\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1307 - mae: 1.4362 - val_loss: 14.0541 - val_mae: 2.7200\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2862 - mae: 1.4616 - val_loss: 14.2291 - val_mae: 2.7688\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4.2941 - mae: 1.4694 - val_loss: 12.7043 - val_mae: 2.6306\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0552 - mae: 1.4665 - val_loss: 13.3108 - val_mae: 2.7073\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3974 - mae: 1.4544 - val_loss: 12.4165 - val_mae: 2.6228\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0767 - mae: 1.4019 - val_loss: 12.1738 - val_mae: 2.6093\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7298 - mae: 1.5052 - val_loss: 11.5140 - val_mae: 2.5420\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.5847 - mae: 1.3504 - val_loss: 13.2730 - val_mae: 2.6986\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.0178 - mae: 1.4254 - val_loss: 13.3009 - val_mae: 2.6731\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.6858 - mae: 1.5190 - val_loss: 12.7338 - val_mae: 2.6289\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9255 - mae: 1.4198 - val_loss: 13.3315 - val_mae: 2.6553\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.8839 - mae: 1.4245 - val_loss: 13.0335 - val_mae: 2.6323\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.8066 - mae: 1.3834 - val_loss: 14.0900 - val_mae: 2.7379\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6531 - mae: 1.4231 - val_loss: 15.5483 - val_mae: 2.7993\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1504 - mae: 1.4319 - val_loss: 11.6265 - val_mae: 2.5334\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.9980 - mae: 1.3848 - val_loss: 11.5655 - val_mae: 2.5956\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7918 - mae: 1.3554 - val_loss: 14.0070 - val_mae: 2.7854\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.5418 - mae: 1.3539 - val_loss: 12.0557 - val_mae: 2.6363\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1842 - mae: 1.4605 - val_loss: 14.4784 - val_mae: 2.7426\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0629 - mae: 1.4529 - val_loss: 14.5393 - val_mae: 2.8432\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9678 - mae: 1.2163 - val_loss: 16.8272 - val_mae: 3.0368\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3862 - mae: 1.3318 - val_loss: 15.0941 - val_mae: 2.7452\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0297 - mae: 1.4436 - val_loss: 14.2813 - val_mae: 2.7533\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8898 - mae: 1.3875 - val_loss: 15.4104 - val_mae: 2.8763\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5615 - mae: 1.3848 - val_loss: 15.2016 - val_mae: 2.8214\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4557 - mae: 1.3434 - val_loss: 11.8701 - val_mae: 2.5998\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6198 - mae: 1.3795 - val_loss: 13.4229 - val_mae: 2.7017\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3919 - mae: 1.2791 - val_loss: 13.4944 - val_mae: 2.7212\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4569 - mae: 1.2970 - val_loss: 13.1252 - val_mae: 2.6563\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3220 - mae: 1.3537 - val_loss: 12.6032 - val_mae: 2.6056\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.1696 - mae: 1.2747 - val_loss: 13.0971 - val_mae: 2.7390\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1649 - mae: 1.3311 - val_loss: 13.6198 - val_mae: 2.8833\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8340 - mae: 1.3709 - val_loss: 15.5645 - val_mae: 2.8609\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7991 - mae: 1.3798 - val_loss: 13.7581 - val_mae: 2.6865\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7859 - mae: 1.2100 - val_loss: 15.1907 - val_mae: 2.7481\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.7595 - mae: 1.3610 - val_loss: 11.7779 - val_mae: 2.6081\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8358 - mae: 1.3336 - val_loss: 13.1124 - val_mae: 2.6378\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3299 - mae: 1.2812 - val_loss: 15.2091 - val_mae: 2.7543\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4759 - mae: 1.3553 - val_loss: 14.6482 - val_mae: 2.6844\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.6738 - mae: 1.3845 - val_loss: 12.7276 - val_mae: 2.5944\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4200 - mae: 1.3304 - val_loss: 11.3458 - val_mae: 2.5586\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7389 - mae: 1.3999 - val_loss: 13.0047 - val_mae: 2.6253\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2162 - mae: 1.2736 - val_loss: 13.1909 - val_mae: 2.6037\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6880 - mae: 1.2041 - val_loss: 12.6084 - val_mae: 2.5752\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6192 - mae: 1.3265 - val_loss: 13.8828 - val_mae: 2.7086\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3739 - mae: 1.2528 - val_loss: 18.1146 - val_mae: 3.1245\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6807 - mae: 1.3695 - val_loss: 15.3841 - val_mae: 2.7896\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4540 - mae: 1.3010 - val_loss: 14.1303 - val_mae: 2.7333\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7789 - mae: 1.3681 - val_loss: 12.8434 - val_mae: 2.6905\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.0535 - mae: 1.1940 - val_loss: 13.3599 - val_mae: 2.6522\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4503 - mae: 1.1057 - val_loss: 18.2905 - val_mae: 2.9543\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5814 - mae: 1.3624 - val_loss: 14.1773 - val_mae: 2.7952\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.1534 - mae: 1.2649 - val_loss: 13.4837 - val_mae: 2.7404\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2259 - mae: 1.2610 - val_loss: 13.8466 - val_mae: 2.6616\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7314 - mae: 1.1791 - val_loss: 16.4121 - val_mae: 2.8353\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.1324 - mae: 1.2380 - val_loss: 14.5921 - val_mae: 2.7090\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3324 - mae: 1.3023 - val_loss: 15.9370 - val_mae: 2.7832\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7998 - mae: 1.2361 - val_loss: 15.9008 - val_mae: 2.7784\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8794 - mae: 1.2180 - val_loss: 13.1477 - val_mae: 2.6475\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2005 - mae: 1.2858 - val_loss: 14.8340 - val_mae: 2.7495\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.1138 - mae: 1.2065 - val_loss: 13.8810 - val_mae: 2.6509\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3764 - mae: 1.1050 - val_loss: 12.1621 - val_mae: 2.5599\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6317 - mae: 1.1656 - val_loss: 12.5119 - val_mae: 2.6440\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2486 - mae: 1.1886 - val_loss: 13.8254 - val_mae: 2.6974\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9304 - mae: 1.2256 - val_loss: 12.4316 - val_mae: 2.5482\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9228 - mae: 1.1818 - val_loss: 13.6627 - val_mae: 2.8503\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2094 - mae: 1.2367 - val_loss: 14.8577 - val_mae: 2.8162\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6542 - mae: 1.1751 - val_loss: 16.2552 - val_mae: 2.8298\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9557 - mae: 1.2333 - val_loss: 15.9491 - val_mae: 2.9152\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0265 - mae: 1.2205 - val_loss: 12.3424 - val_mae: 2.6462\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5898 - mae: 1.3136 - val_loss: 16.1489 - val_mae: 2.8662\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 2.7588 - mae: 1.1419 - val_loss: 15.9738 - val_mae: 2.8101\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5766 - mae: 1.1582 - val_loss: 14.6465 - val_mae: 2.7577\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8299 - mae: 1.1547 - val_loss: 14.9442 - val_mae: 2.7208\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.6735 - mae: 1.1978 - val_loss: 15.8408 - val_mae: 2.7779\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5364 - mae: 1.1240 - val_loss: 12.1413 - val_mae: 2.6277\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7494 - mae: 1.1934 - val_loss: 13.2353 - val_mae: 2.6684\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5554 - mae: 1.2294 - val_loss: 13.6014 - val_mae: 2.6820\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2403 - mae: 1.0036 - val_loss: 14.6238 - val_mae: 2.6836\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3850 - mae: 1.0990 - val_loss: 16.0033 - val_mae: 2.8710\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9878 - mae: 1.2295 - val_loss: 15.8396 - val_mae: 2.8024\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9453 - mae: 1.1759 - val_loss: 16.8668 - val_mae: 2.9141\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4520 - mae: 1.1632 - val_loss: 15.7194 - val_mae: 2.9456\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6273 - mae: 1.1726 - val_loss: 16.7225 - val_mae: 2.9101\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3362 - mae: 1.1248 - val_loss: 13.3915 - val_mae: 2.6473\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.1046 - mae: 1.1595 - val_loss: 14.5668 - val_mae: 2.7505\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.2313 - mae: 1.1852 - val_loss: 13.2834 - val_mae: 2.5877\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3.1622 - mae: 1.1695 - val_loss: 17.3725 - val_mae: 2.9660\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4747 - mae: 1.1119 - val_loss: 14.4666 - val_mae: 2.7242\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9202 - mae: 1.1260 - val_loss: 14.3499 - val_mae: 2.8472\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7329 - mae: 1.1982 - val_loss: 15.6080 - val_mae: 2.8074\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.2056 - mae: 1.2338 - val_loss: 15.1620 - val_mae: 2.7043\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8511 - mae: 1.1512 - val_loss: 13.5899 - val_mae: 2.6773\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4385 - mae: 1.1299 - val_loss: 13.3452 - val_mae: 2.6688\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8802 - mae: 1.1820 - val_loss: 18.3333 - val_mae: 3.0374\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.6984 - mae: 1.1516 - val_loss: 14.3114 - val_mae: 2.7749\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3186 - mae: 1.2544 - val_loss: 13.9249 - val_mae: 2.6699\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7778 - mae: 1.1283 - val_loss: 14.3038 - val_mae: 2.6963\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6305 - mae: 1.1733 - val_loss: 11.7487 - val_mae: 2.5710\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.0717 - mae: 1.2249 - val_loss: 17.6461 - val_mae: 2.9291\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7097 - mae: 1.1871 - val_loss: 15.3689 - val_mae: 2.8742\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7234 - mae: 1.1302 - val_loss: 13.9051 - val_mae: 2.6266\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1806 - mae: 1.0389 - val_loss: 14.1128 - val_mae: 2.7921\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4275 - mae: 1.1200 - val_loss: 14.8465 - val_mae: 2.8114\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5893 - mae: 1.1019 - val_loss: 17.6652 - val_mae: 3.0579\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5374 - mae: 1.1530 - val_loss: 13.3001 - val_mae: 2.6695\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4177 - mae: 1.0965 - val_loss: 14.0859 - val_mae: 2.7052\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0558 - mae: 1.0523 - val_loss: 16.2827 - val_mae: 2.9434\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6655 - mae: 1.1285 - val_loss: 18.3145 - val_mae: 3.1469\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.8646 - mae: 1.1948 - val_loss: 13.1976 - val_mae: 2.5988\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4680 - mae: 1.1315 - val_loss: 16.3532 - val_mae: 2.8413\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1314 - mae: 1.0941 - val_loss: 17.0208 - val_mae: 2.8436\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1081 - mae: 0.9876 - val_loss: 15.5881 - val_mae: 2.7444\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4401 - mae: 1.0585 - val_loss: 12.8987 - val_mae: 2.5766\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8196 - mae: 1.1558 - val_loss: 15.6246 - val_mae: 2.8029\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9857 - mae: 1.0029 - val_loss: 16.8850 - val_mae: 2.9542\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5592 - mae: 1.1091 - val_loss: 15.9249 - val_mae: 2.8580\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5483 - mae: 1.0550 - val_loss: 15.4897 - val_mae: 2.7481\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3778 - mae: 1.1075 - val_loss: 14.4658 - val_mae: 2.6985\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8715 - mae: 1.1705 - val_loss: 12.9515 - val_mae: 2.5750\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7687 - mae: 1.1250 - val_loss: 15.8162 - val_mae: 2.7993\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8684 - mae: 1.1971 - val_loss: 14.1564 - val_mae: 2.6585\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1341 - mae: 0.9510 - val_loss: 14.8418 - val_mae: 2.7154\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3919 - mae: 1.0842 - val_loss: 14.2285 - val_mae: 2.6192\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.3779 - mae: 1.1189 - val_loss: 16.1369 - val_mae: 2.9567\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1193 - mae: 1.0590 - val_loss: 13.5980 - val_mae: 2.5894\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2232 - mae: 1.0909 - val_loss: 14.3186 - val_mae: 2.6359\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9557 - mae: 1.0109 - val_loss: 15.8498 - val_mae: 2.8386\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3226 - mae: 1.0610 - val_loss: 14.5494 - val_mae: 2.7891\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0187 - mae: 1.0462 - val_loss: 18.3095 - val_mae: 3.1188\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5792 - mae: 1.1237 - val_loss: 16.2313 - val_mae: 2.9629\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8666 - mae: 0.9987 - val_loss: 17.0942 - val_mae: 2.9330\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9012 - mae: 1.0065 - val_loss: 14.7439 - val_mae: 2.6494\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1622 - mae: 1.0915 - val_loss: 15.2341 - val_mae: 2.6879\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8037 - mae: 0.9793 - val_loss: 14.4157 - val_mae: 2.6486\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1878 - mae: 1.0835 - val_loss: 13.8029 - val_mae: 2.6683\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9437 - mae: 0.9939 - val_loss: 16.4076 - val_mae: 2.8369\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5967 - mae: 0.9405 - val_loss: 14.5317 - val_mae: 2.7206\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5411 - mae: 1.1028 - val_loss: 14.3009 - val_mae: 2.6515\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0705 - mae: 1.0056 - val_loss: 13.1903 - val_mae: 2.5767\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3185 - mae: 1.0881 - val_loss: 15.7640 - val_mae: 2.7720\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5450 - mae: 1.0960 - val_loss: 15.2222 - val_mae: 2.6854\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8181 - mae: 1.0025 - val_loss: 14.2158 - val_mae: 2.5998\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8867 - mae: 0.9869 - val_loss: 15.1266 - val_mae: 2.6300\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0549 - mae: 1.0262 - val_loss: 16.7768 - val_mae: 2.8541\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7603 - mae: 0.9702 - val_loss: 15.5931 - val_mae: 2.7220\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0350 - mae: 0.9909 - val_loss: 14.1254 - val_mae: 2.6722\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0091 - mae: 1.0037 - val_loss: 13.0061 - val_mae: 2.5572\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8708 - mae: 0.9852 - val_loss: 14.7695 - val_mae: 2.7770\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3106 - mae: 1.0430 - val_loss: 17.1839 - val_mae: 2.9424\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.9565 - mae: 0.9581 - val_loss: 14.6625 - val_mae: 2.7211\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.7400 - mae: 0.9313 - val_loss: 17.3510 - val_mae: 2.7665\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0139 - mae: 0.9866 - val_loss: 17.0747 - val_mae: 2.9453\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9911 - mae: 1.0181 - val_loss: 13.8265 - val_mae: 2.6700\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.6860 - mae: 0.9204 - val_loss: 13.4757 - val_mae: 2.5797\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7684 - mae: 0.9533 - val_loss: 14.8634 - val_mae: 2.7194\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8798 - mae: 0.9541 - val_loss: 18.3147 - val_mae: 3.0468\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0105 - mae: 0.9862 - val_loss: 13.7913 - val_mae: 2.5595\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7753 - mae: 0.9058 - val_loss: 16.2353 - val_mae: 2.6931\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9061 - mae: 0.9911 - val_loss: 14.5961 - val_mae: 2.5972\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7651 - mae: 0.9356 - val_loss: 14.3752 - val_mae: 2.5666\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9959 - mae: 1.0057 - val_loss: 17.0148 - val_mae: 2.9364\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8791 - mae: 0.9862 - val_loss: 14.6177 - val_mae: 2.6125\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.4740 - mae: 0.8626 - val_loss: 20.0789 - val_mae: 3.0450\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1731 - mae: 1.0286 - val_loss: 16.7764 - val_mae: 2.8597\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.6415 - mae: 0.9151 - val_loss: 14.9576 - val_mae: 2.6308\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5119 - mae: 0.8624 - val_loss: 20.6363 - val_mae: 3.2993\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1036 - mae: 1.0811 - val_loss: 15.9769 - val_mae: 2.8650\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9013 - mae: 1.0247 - val_loss: 15.9227 - val_mae: 2.6472\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5607 - mae: 0.8785 - val_loss: 14.9066 - val_mae: 2.6171\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5348 - mae: 0.8942 - val_loss: 16.1394 - val_mae: 2.7960\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5558 - mae: 0.8412 - val_loss: 19.2290 - val_mae: 3.0766\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.3144 - mae: 0.8268 - val_loss: 15.6941 - val_mae: 2.8144\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7219 - mae: 0.9522 - val_loss: 15.8381 - val_mae: 2.6506\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5312 - mae: 0.8937 - val_loss: 21.0584 - val_mae: 3.4106\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0798 - mae: 1.0489 - val_loss: 14.7362 - val_mae: 2.6597\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.7734 - mae: 0.9298 - val_loss: 14.1018 - val_mae: 2.5502\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4354 - mae: 0.8615 - val_loss: 15.3044 - val_mae: 2.7779\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8311 - mae: 0.9822 - val_loss: 14.2289 - val_mae: 2.6533\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7884 - mae: 0.9706 - val_loss: 18.3980 - val_mae: 2.7662\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7642 - mae: 0.9312 - val_loss: 14.7031 - val_mae: 2.6341\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5659 - mae: 0.9157 - val_loss: 14.7195 - val_mae: 2.5704\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.4317 - mae: 0.8377 - val_loss: 17.0769 - val_mae: 2.8404\n",
            "processing fold # 2\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 16ms/step - loss: 567.5272 - mae: 21.7692 - val_loss: 452.1379 - val_mae: 20.0139\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 472.8172 - mae: 19.7284 - val_loss: 363.2729 - val_mae: 17.5594\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 368.8516 - mae: 16.8186 - val_loss: 261.5669 - val_mae: 14.5255\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 291.1322 - mae: 14.7267 - val_loss: 165.1678 - val_mae: 11.1427\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 184.4860 - mae: 10.9875 - val_loss: 92.9867 - val_mae: 8.1594\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 89.3997 - mae: 7.3092 - val_loss: 50.7732 - val_mae: 5.9562\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 62.1468 - mae: 5.7788 - val_loss: 32.3682 - val_mae: 4.6295\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 52.4415 - mae: 5.0515 - val_loss: 23.6544 - val_mae: 3.8683\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 35.0828 - mae: 4.1270 - val_loss: 18.7214 - val_mae: 3.4215\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 28.8384 - mae: 3.6027 - val_loss: 16.6666 - val_mae: 3.1916\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 29.3122 - mae: 3.6059 - val_loss: 15.4771 - val_mae: 3.0532\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 28.9914 - mae: 3.5860 - val_loss: 14.2929 - val_mae: 2.8648\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 20.4902 - mae: 2.9628 - val_loss: 13.8728 - val_mae: 2.8628\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 20.4903 - mae: 3.1471 - val_loss: 12.7222 - val_mae: 2.7051\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 21.2366 - mae: 3.0087 - val_loss: 12.6824 - val_mae: 2.7501\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 18.8165 - mae: 2.8477 - val_loss: 12.1166 - val_mae: 2.6800\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 12.7703 - mae: 2.4740 - val_loss: 12.2725 - val_mae: 2.6576\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 16.0897 - mae: 2.6431 - val_loss: 12.0971 - val_mae: 2.7001\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 15.4025 - mae: 2.7029 - val_loss: 10.9669 - val_mae: 2.5515\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 13.0780 - mae: 2.5273 - val_loss: 10.7834 - val_mae: 2.5441\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.9409 - mae: 2.4497 - val_loss: 10.9866 - val_mae: 2.6083\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.9839 - mae: 2.3569 - val_loss: 10.4714 - val_mae: 2.5604\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 16.8302 - mae: 2.5768 - val_loss: 9.9740 - val_mae: 2.4843\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 17.2968 - mae: 2.5434 - val_loss: 10.6548 - val_mae: 2.6083\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 14.4768 - mae: 2.5418 - val_loss: 10.0166 - val_mae: 2.5153\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.8603 - mae: 2.2701 - val_loss: 9.9589 - val_mae: 2.4639\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.5872 - mae: 2.2176 - val_loss: 10.3594 - val_mae: 2.5667\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 13.0824 - mae: 2.3822 - val_loss: 10.0611 - val_mae: 2.5274\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.3332 - mae: 2.2619 - val_loss: 10.6410 - val_mae: 2.6097\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.3254 - mae: 2.2803 - val_loss: 10.7993 - val_mae: 2.6213\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 16.3791 - mae: 2.6721 - val_loss: 10.0332 - val_mae: 2.5009\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 12.4781 - mae: 2.3541 - val_loss: 10.1527 - val_mae: 2.5357\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 11.1182 - mae: 2.2077 - val_loss: 9.8460 - val_mae: 2.4818\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.9286 - mae: 2.2800 - val_loss: 10.1905 - val_mae: 2.5367\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.4304 - mae: 2.0805 - val_loss: 10.7834 - val_mae: 2.6298\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.8260 - mae: 2.2311 - val_loss: 9.6552 - val_mae: 2.4479\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.0679 - mae: 2.1052 - val_loss: 10.1825 - val_mae: 2.5523\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.2268 - mae: 2.1096 - val_loss: 10.5111 - val_mae: 2.5790\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.2629 - mae: 2.0730 - val_loss: 10.4536 - val_mae: 2.5729\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.0669 - mae: 2.1024 - val_loss: 10.3899 - val_mae: 2.5538\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.9905 - mae: 2.2205 - val_loss: 9.7962 - val_mae: 2.4737\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.8006 - mae: 2.1974 - val_loss: 10.0774 - val_mae: 2.5177\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.3633 - mae: 2.2666 - val_loss: 10.8595 - val_mae: 2.6323\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.5652 - mae: 2.0870 - val_loss: 11.0629 - val_mae: 2.6535\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.9610 - mae: 2.0090 - val_loss: 10.9301 - val_mae: 2.6275\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.8447 - mae: 2.2213 - val_loss: 13.3143 - val_mae: 2.8998\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.7214 - mae: 2.2689 - val_loss: 11.9364 - val_mae: 2.7401\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.2156 - mae: 2.2040 - val_loss: 9.9150 - val_mae: 2.4983\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.5336 - mae: 2.0779 - val_loss: 10.0716 - val_mae: 2.5265\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.2936 - mae: 2.0473 - val_loss: 10.9538 - val_mae: 2.6313\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.3348 - mae: 1.8907 - val_loss: 11.4359 - val_mae: 2.6601\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 11.1233 - mae: 2.1784 - val_loss: 9.5122 - val_mae: 2.4406\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 11.2762 - mae: 2.1636 - val_loss: 9.8989 - val_mae: 2.4881\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.9076 - mae: 1.9709 - val_loss: 10.1842 - val_mae: 2.5253\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.1770 - mae: 2.0078 - val_loss: 10.7825 - val_mae: 2.5821\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.6882 - mae: 2.0167 - val_loss: 10.3495 - val_mae: 2.5516\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.1069 - mae: 2.0667 - val_loss: 10.0010 - val_mae: 2.5053\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.4157 - mae: 1.9430 - val_loss: 8.9596 - val_mae: 2.3618\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.1450 - mae: 1.9318 - val_loss: 10.1673 - val_mae: 2.5113\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.1325 - mae: 1.8530 - val_loss: 10.8546 - val_mae: 2.5857\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.6639 - mae: 2.0987 - val_loss: 11.2558 - val_mae: 2.6302\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.1401 - mae: 1.9906 - val_loss: 9.6146 - val_mae: 2.4726\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.7482 - mae: 1.9207 - val_loss: 9.5353 - val_mae: 2.4336\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.2606 - mae: 1.9626 - val_loss: 10.8034 - val_mae: 2.5834\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.5265 - mae: 1.9408 - val_loss: 9.0724 - val_mae: 2.3814\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.6606 - mae: 1.9124 - val_loss: 9.8433 - val_mae: 2.4769\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.7236 - mae: 1.9916 - val_loss: 10.4264 - val_mae: 2.5266\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.0782 - mae: 1.9562 - val_loss: 10.9428 - val_mae: 2.5955\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.4816 - mae: 2.1651 - val_loss: 8.8379 - val_mae: 2.3486\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.8600 - mae: 1.8465 - val_loss: 10.8193 - val_mae: 2.5733\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.4827 - mae: 1.8103 - val_loss: 9.6247 - val_mae: 2.4342\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.5560 - mae: 1.7993 - val_loss: 9.0775 - val_mae: 2.3612\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.4673 - mae: 1.9552 - val_loss: 9.0785 - val_mae: 2.3780\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.9080 - mae: 1.8991 - val_loss: 8.9940 - val_mae: 2.3729\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.1220 - mae: 1.8058 - val_loss: 9.9880 - val_mae: 2.5025\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.1887 - mae: 2.0057 - val_loss: 9.7381 - val_mae: 2.4513\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.5052 - mae: 1.9068 - val_loss: 9.1907 - val_mae: 2.3991\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.9359 - mae: 1.8005 - val_loss: 9.7247 - val_mae: 2.4739\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.0432 - mae: 1.9188 - val_loss: 9.5578 - val_mae: 2.4293\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.6445 - mae: 1.7920 - val_loss: 9.1574 - val_mae: 2.3755\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 12.0058 - mae: 2.2038 - val_loss: 9.0353 - val_mae: 2.3690\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.1567 - mae: 1.6967 - val_loss: 9.3290 - val_mae: 2.4087\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.0073 - mae: 2.0233 - val_loss: 9.5374 - val_mae: 2.4177\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.3322 - mae: 1.8039 - val_loss: 9.7727 - val_mae: 2.4535\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.3736 - mae: 1.8275 - val_loss: 9.5616 - val_mae: 2.4650\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.1321 - mae: 1.9162 - val_loss: 9.4917 - val_mae: 2.4094\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.2716 - mae: 1.8923 - val_loss: 8.9308 - val_mae: 2.3498\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.0454 - mae: 1.7925 - val_loss: 10.5545 - val_mae: 2.5199\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.0691 - mae: 1.7057 - val_loss: 9.3393 - val_mae: 2.4180\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7239 - mae: 1.8952 - val_loss: 9.6587 - val_mae: 2.4258\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.3425 - mae: 1.9191 - val_loss: 9.1261 - val_mae: 2.3707\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.5972 - mae: 1.6034 - val_loss: 9.7949 - val_mae: 2.4429\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.8169 - mae: 1.7146 - val_loss: 9.1869 - val_mae: 2.3974\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.3126 - mae: 1.8307 - val_loss: 9.7694 - val_mae: 2.4294\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.8178 - mae: 1.6373 - val_loss: 11.1274 - val_mae: 2.5811\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.2927 - mae: 1.6794 - val_loss: 12.3539 - val_mae: 2.6811\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.6219 - mae: 1.7316 - val_loss: 12.3171 - val_mae: 2.6630\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.0894 - mae: 2.0100 - val_loss: 9.3239 - val_mae: 2.3964\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.6856 - mae: 1.6762 - val_loss: 10.1506 - val_mae: 2.5102\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.6715 - mae: 1.7195 - val_loss: 10.4925 - val_mae: 2.5137\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.1223 - mae: 1.7022 - val_loss: 9.1901 - val_mae: 2.3868\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.5651 - mae: 1.6906 - val_loss: 9.1783 - val_mae: 2.4120\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.2346 - mae: 1.6433 - val_loss: 9.5864 - val_mae: 2.4214\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.3028 - mae: 1.6403 - val_loss: 10.9172 - val_mae: 2.5400\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.5474 - mae: 1.7963 - val_loss: 8.6712 - val_mae: 2.3417\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.2032 - mae: 1.6123 - val_loss: 11.1999 - val_mae: 2.5663\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.6071 - mae: 1.7969 - val_loss: 9.0157 - val_mae: 2.3752\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.2624 - mae: 1.6343 - val_loss: 11.3318 - val_mae: 2.6088\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.5945 - mae: 1.5641 - val_loss: 9.0180 - val_mae: 2.3616\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1355 - mae: 1.4672 - val_loss: 12.8274 - val_mae: 2.7037\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.7843 - mae: 1.7667 - val_loss: 9.9142 - val_mae: 2.4797\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.9897 - mae: 1.5774 - val_loss: 10.1400 - val_mae: 2.4480\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.5361 - mae: 1.5376 - val_loss: 9.8078 - val_mae: 2.4267\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1737 - mae: 1.6291 - val_loss: 9.8462 - val_mae: 2.4295\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7086 - mae: 1.5801 - val_loss: 8.6168 - val_mae: 2.3390\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.5923 - mae: 1.5747 - val_loss: 9.6471 - val_mae: 2.4052\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0984 - mae: 1.6016 - val_loss: 9.8634 - val_mae: 2.4279\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.4265 - mae: 1.4518 - val_loss: 11.6097 - val_mae: 2.6255\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.0495 - mae: 1.6170 - val_loss: 9.1929 - val_mae: 2.3795\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.4110 - mae: 1.5517 - val_loss: 10.2074 - val_mae: 2.4591\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1051 - mae: 1.4887 - val_loss: 11.9230 - val_mae: 2.7022\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.0526 - mae: 1.7146 - val_loss: 10.5832 - val_mae: 2.5174\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.3497 - mae: 1.6299 - val_loss: 9.2082 - val_mae: 2.3840\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.7341 - mae: 1.5994 - val_loss: 9.7215 - val_mae: 2.4265\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3550 - mae: 1.5481 - val_loss: 10.3666 - val_mae: 2.4614\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.9358 - mae: 1.7654 - val_loss: 9.0356 - val_mae: 2.3381\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2570 - mae: 1.4732 - val_loss: 9.8255 - val_mae: 2.4216\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7614 - mae: 1.5111 - val_loss: 9.9657 - val_mae: 2.4748\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.4128 - mae: 1.5222 - val_loss: 8.8591 - val_mae: 2.3519\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2715 - mae: 1.4660 - val_loss: 8.9545 - val_mae: 2.3735\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.7044 - mae: 1.6599 - val_loss: 12.0155 - val_mae: 2.6249\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.2944 - mae: 1.6539 - val_loss: 10.0385 - val_mae: 2.4494\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0315 - mae: 1.5338 - val_loss: 9.6707 - val_mae: 2.4237\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0145 - mae: 1.4351 - val_loss: 10.1341 - val_mae: 2.4656\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.6446 - mae: 1.5109 - val_loss: 8.8515 - val_mae: 2.3584\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.8960 - mae: 1.7821 - val_loss: 9.0429 - val_mae: 2.3623\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9668 - mae: 1.4216 - val_loss: 8.4876 - val_mae: 2.3198\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.3825 - mae: 1.6106 - val_loss: 11.0091 - val_mae: 2.5707\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1866 - mae: 1.6049 - val_loss: 8.7530 - val_mae: 2.3550\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2973 - mae: 1.5073 - val_loss: 9.6685 - val_mae: 2.4451\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8161 - mae: 1.6466 - val_loss: 9.7829 - val_mae: 2.4567\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.3533 - mae: 1.5987 - val_loss: 9.9607 - val_mae: 2.4889\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.2792 - mae: 1.5120 - val_loss: 9.7010 - val_mae: 2.4865\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8094 - mae: 1.4361 - val_loss: 10.2964 - val_mae: 2.5342\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1840 - mae: 1.5372 - val_loss: 10.9523 - val_mae: 2.5186\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0390 - mae: 1.4242 - val_loss: 9.3459 - val_mae: 2.4276\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7585 - mae: 1.5115 - val_loss: 9.4504 - val_mae: 2.4017\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2625 - mae: 1.4804 - val_loss: 9.9045 - val_mae: 2.4100\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.3345 - mae: 1.4837 - val_loss: 9.7435 - val_mae: 2.4490\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4252 - mae: 1.2814 - val_loss: 9.9421 - val_mae: 2.4492\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6867 - mae: 1.3606 - val_loss: 11.3863 - val_mae: 2.5942\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8624 - mae: 1.5380 - val_loss: 13.8074 - val_mae: 2.7714\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.9243 - mae: 1.5646 - val_loss: 9.3966 - val_mae: 2.3923\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9458 - mae: 1.3878 - val_loss: 8.7529 - val_mae: 2.3535\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2016 - mae: 1.4684 - val_loss: 10.0820 - val_mae: 2.4639\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.4932 - mae: 1.4590 - val_loss: 9.8880 - val_mae: 2.4681\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.0225 - mae: 1.3909 - val_loss: 8.9752 - val_mae: 2.3911\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.4168 - mae: 1.4529 - val_loss: 9.5246 - val_mae: 2.4577\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8749 - mae: 1.4973 - val_loss: 9.1473 - val_mae: 2.3639\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.9155 - mae: 1.3932 - val_loss: 9.8150 - val_mae: 2.4514\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.4421 - mae: 1.3116 - val_loss: 9.7374 - val_mae: 2.4172\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0467 - mae: 1.5079 - val_loss: 10.8506 - val_mae: 2.5222\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9361 - mae: 1.4198 - val_loss: 8.3983 - val_mae: 2.2934\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8881 - mae: 1.3883 - val_loss: 11.4637 - val_mae: 2.5820\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7672 - mae: 1.3999 - val_loss: 9.3521 - val_mae: 2.3762\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.5581 - mae: 1.3105 - val_loss: 9.1003 - val_mae: 2.3472\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8262 - mae: 1.3877 - val_loss: 8.5256 - val_mae: 2.3191\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.0676 - mae: 1.3791 - val_loss: 11.1605 - val_mae: 2.5748\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2654 - mae: 1.3152 - val_loss: 10.5638 - val_mae: 2.5426\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2686 - mae: 1.5162 - val_loss: 9.7361 - val_mae: 2.4037\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8958 - mae: 1.4220 - val_loss: 10.9925 - val_mae: 2.5402\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1071 - mae: 1.4442 - val_loss: 11.0980 - val_mae: 2.5313\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3247 - mae: 1.2773 - val_loss: 10.1155 - val_mae: 2.4750\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.5424 - mae: 1.3358 - val_loss: 9.2771 - val_mae: 2.4107\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3775 - mae: 1.3706 - val_loss: 10.5129 - val_mae: 2.4780\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.3094 - mae: 1.3980 - val_loss: 8.0562 - val_mae: 2.2735\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0152 - mae: 1.2496 - val_loss: 9.7724 - val_mae: 2.4277\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2131 - mae: 1.2963 - val_loss: 8.4806 - val_mae: 2.3312\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5945 - mae: 1.3519 - val_loss: 8.9871 - val_mae: 2.3414\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6925 - mae: 1.3671 - val_loss: 12.4165 - val_mae: 2.6626\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7085 - mae: 1.4914 - val_loss: 10.0922 - val_mae: 2.4483\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1242 - mae: 1.3209 - val_loss: 10.1882 - val_mae: 2.4554\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1462 - mae: 1.3466 - val_loss: 10.0865 - val_mae: 2.4672\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3866 - mae: 1.3790 - val_loss: 9.2500 - val_mae: 2.3766\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7647 - mae: 1.2349 - val_loss: 10.0680 - val_mae: 2.4350\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8571 - mae: 1.2103 - val_loss: 10.8962 - val_mae: 2.5353\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2030 - mae: 1.2598 - val_loss: 8.8823 - val_mae: 2.3525\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.8681 - mae: 1.3882 - val_loss: 10.2665 - val_mae: 2.4500\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2957 - mae: 1.3072 - val_loss: 9.7102 - val_mae: 2.3865\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4730 - mae: 1.1350 - val_loss: 11.4144 - val_mae: 2.6075\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9740 - mae: 1.4238 - val_loss: 9.7259 - val_mae: 2.4264\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7923 - mae: 1.4066 - val_loss: 10.2246 - val_mae: 2.4788\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9322 - mae: 1.2576 - val_loss: 10.2338 - val_mae: 2.4554\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.9196 - mae: 1.2437 - val_loss: 9.3810 - val_mae: 2.3713\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3935 - mae: 1.3427 - val_loss: 10.9197 - val_mae: 2.5025\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0485 - mae: 1.2856 - val_loss: 8.8418 - val_mae: 2.3262\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3012 - mae: 1.3168 - val_loss: 11.5565 - val_mae: 2.5665\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3734 - mae: 1.3165 - val_loss: 10.4459 - val_mae: 2.5033\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0657 - mae: 1.2805 - val_loss: 9.6966 - val_mae: 2.3826\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7779 - mae: 1.2270 - val_loss: 11.2177 - val_mae: 2.5422\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.9942 - mae: 1.2550 - val_loss: 8.7417 - val_mae: 2.3008\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9549 - mae: 1.2824 - val_loss: 9.3397 - val_mae: 2.3660\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5375 - mae: 1.3229 - val_loss: 11.6189 - val_mae: 2.5766\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2365 - mae: 1.3367 - val_loss: 9.8819 - val_mae: 2.4257\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7247 - mae: 1.1570 - val_loss: 10.3028 - val_mae: 2.4505\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6930 - mae: 1.2253 - val_loss: 10.2243 - val_mae: 2.4961\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.8309 - mae: 1.2589 - val_loss: 10.2934 - val_mae: 2.4409\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6505 - mae: 1.2273 - val_loss: 10.5950 - val_mae: 2.4623\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7850 - mae: 1.1547 - val_loss: 10.2734 - val_mae: 2.4827\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4888 - mae: 1.1504 - val_loss: 10.5376 - val_mae: 2.4758\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3922 - mae: 1.2483 - val_loss: 8.6161 - val_mae: 2.3087\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6670 - mae: 1.2923 - val_loss: 9.1818 - val_mae: 2.3316\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.1163 - mae: 1.2337 - val_loss: 10.1929 - val_mae: 2.4412\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3707 - mae: 1.2619 - val_loss: 8.5788 - val_mae: 2.2857\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5078 - mae: 1.1801 - val_loss: 9.3080 - val_mae: 2.3392\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2923 - mae: 1.2094 - val_loss: 8.7769 - val_mae: 2.3294\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5441 - mae: 1.2774 - val_loss: 8.7755 - val_mae: 2.3508\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8412 - mae: 1.1877 - val_loss: 11.1979 - val_mae: 2.5145\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.2456 - mae: 1.2808 - val_loss: 9.3787 - val_mae: 2.3400\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.2057 - mae: 1.2514 - val_loss: 11.9834 - val_mae: 2.5864\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8299 - mae: 1.2619 - val_loss: 9.0233 - val_mae: 2.3607\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.6291 - mae: 1.3099 - val_loss: 9.8844 - val_mae: 2.4448\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2664 - mae: 1.1329 - val_loss: 8.9107 - val_mae: 2.3064\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0925 - mae: 1.2333 - val_loss: 8.2378 - val_mae: 2.2570\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4196 - mae: 1.1203 - val_loss: 9.1480 - val_mae: 2.3501\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6028 - mae: 1.1705 - val_loss: 10.2101 - val_mae: 2.4278\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6072 - mae: 1.1856 - val_loss: 10.7136 - val_mae: 2.5436\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5974 - mae: 1.1582 - val_loss: 8.9989 - val_mae: 2.3019\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4524 - mae: 1.1230 - val_loss: 10.7468 - val_mae: 2.4771\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9637 - mae: 1.1604 - val_loss: 10.6250 - val_mae: 2.5168\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7763 - mae: 1.2342 - val_loss: 9.1596 - val_mae: 2.2882\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1166 - mae: 1.0468 - val_loss: 12.1281 - val_mae: 2.7053\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.8913 - mae: 1.2421 - val_loss: 9.1730 - val_mae: 2.3461\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.3362 - mae: 1.1105 - val_loss: 10.6897 - val_mae: 2.4663\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5836 - mae: 1.1178 - val_loss: 9.4601 - val_mae: 2.3388\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5215 - mae: 1.1666 - val_loss: 9.1328 - val_mae: 2.3972\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9501 - mae: 1.1911 - val_loss: 9.7184 - val_mae: 2.4011\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6775 - mae: 1.2207 - val_loss: 10.0309 - val_mae: 2.3803\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0838 - mae: 1.2597 - val_loss: 10.4089 - val_mae: 2.4683\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3287 - mae: 1.1195 - val_loss: 10.2647 - val_mae: 2.4197\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0110 - mae: 1.0376 - val_loss: 10.4289 - val_mae: 2.4555\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1390 - mae: 1.0411 - val_loss: 8.6572 - val_mae: 2.3221\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7741 - mae: 1.2123 - val_loss: 9.6486 - val_mae: 2.3582\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4078 - mae: 1.1091 - val_loss: 8.9728 - val_mae: 2.3758\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2084 - mae: 1.0540 - val_loss: 9.0664 - val_mae: 2.3392\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1335 - mae: 1.0345 - val_loss: 11.0233 - val_mae: 2.5193\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6094 - mae: 1.1285 - val_loss: 9.8447 - val_mae: 2.4059\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4142 - mae: 1.0839 - val_loss: 10.2968 - val_mae: 2.4320\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9736 - mae: 1.0140 - val_loss: 9.0849 - val_mae: 2.3544\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3051 - mae: 1.1425 - val_loss: 9.1078 - val_mae: 2.3671\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.9878 - mae: 1.0162 - val_loss: 9.7516 - val_mae: 2.3854\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2674 - mae: 1.0918 - val_loss: 8.7397 - val_mae: 2.3124\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2446 - mae: 1.0951 - val_loss: 11.1948 - val_mae: 2.5362\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9317 - mae: 1.0191 - val_loss: 10.1030 - val_mae: 2.4423\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9208 - mae: 1.1615 - val_loss: 9.6420 - val_mae: 2.4099\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0972 - mae: 1.0752 - val_loss: 9.7697 - val_mae: 2.4075\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2697 - mae: 1.1018 - val_loss: 8.7061 - val_mae: 2.3230\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4374 - mae: 1.1169 - val_loss: 8.9876 - val_mae: 2.3306\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0176 - mae: 1.0747 - val_loss: 9.9345 - val_mae: 2.4105\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2262 - mae: 1.0469 - val_loss: 12.3661 - val_mae: 2.6697\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4202 - mae: 1.1649 - val_loss: 10.6876 - val_mae: 2.4898\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4280 - mae: 1.0617 - val_loss: 14.2367 - val_mae: 2.8862\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7867 - mae: 1.2636 - val_loss: 8.9328 - val_mae: 2.3315\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9021 - mae: 0.9647 - val_loss: 9.2250 - val_mae: 2.3312\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0479 - mae: 1.0272 - val_loss: 10.0451 - val_mae: 2.4105\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1319 - mae: 1.0685 - val_loss: 9.5184 - val_mae: 2.3785\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9446 - mae: 0.9918 - val_loss: 10.0665 - val_mae: 2.4046\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1236 - mae: 1.0383 - val_loss: 9.1260 - val_mae: 2.3141\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0139 - mae: 0.9871 - val_loss: 9.7990 - val_mae: 2.3845\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.8606 - mae: 0.9452 - val_loss: 9.9627 - val_mae: 2.4302\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9470 - mae: 1.0386 - val_loss: 10.1053 - val_mae: 2.3987\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1047 - mae: 0.9993 - val_loss: 10.2731 - val_mae: 2.4452\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1948 - mae: 1.0738 - val_loss: 14.1516 - val_mae: 2.9002\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3438 - mae: 1.1323 - val_loss: 10.4721 - val_mae: 2.4645\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8992 - mae: 1.0094 - val_loss: 12.4560 - val_mae: 2.7278\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1231 - mae: 1.0518 - val_loss: 8.9196 - val_mae: 2.3082\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3652 - mae: 1.0647 - val_loss: 9.6757 - val_mae: 2.3776\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.5001 - mae: 1.0874 - val_loss: 9.2662 - val_mae: 2.3456\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8771 - mae: 0.9920 - val_loss: 10.6817 - val_mae: 2.4761\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4946 - mae: 1.1433 - val_loss: 8.8599 - val_mae: 2.3667\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6297 - mae: 1.1127 - val_loss: 11.1855 - val_mae: 2.5534\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8782 - mae: 0.9458 - val_loss: 9.7917 - val_mae: 2.3859\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9903 - mae: 1.0029 - val_loss: 9.0169 - val_mae: 2.3505\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3073 - mae: 1.0824 - val_loss: 9.9500 - val_mae: 2.4072\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2296 - mae: 1.0304 - val_loss: 13.2267 - val_mae: 2.7487\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6290 - mae: 1.1770 - val_loss: 9.1408 - val_mae: 2.3754\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.7151 - mae: 0.9670 - val_loss: 11.7405 - val_mae: 2.5747\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5824 - mae: 1.1174 - val_loss: 9.2371 - val_mae: 2.4304\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9118 - mae: 1.0192 - val_loss: 9.5142 - val_mae: 2.3828\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7615 - mae: 1.0979 - val_loss: 8.9063 - val_mae: 2.3373\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9265 - mae: 0.9914 - val_loss: 12.2707 - val_mae: 2.6511\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7191 - mae: 1.1302 - val_loss: 10.4872 - val_mae: 2.4737\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5233 - mae: 1.1010 - val_loss: 10.2589 - val_mae: 2.5314\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1293 - mae: 1.0493 - val_loss: 9.3249 - val_mae: 2.3276\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7517 - mae: 0.9829 - val_loss: 15.6728 - val_mae: 2.9931\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8135 - mae: 1.1813 - val_loss: 10.8648 - val_mae: 2.4739\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.8475 - mae: 1.0279 - val_loss: 10.3540 - val_mae: 2.4364\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8972 - mae: 0.9682 - val_loss: 9.6468 - val_mae: 2.3842\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6593 - mae: 0.9051 - val_loss: 11.4013 - val_mae: 2.5692\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.9200 - mae: 0.9741 - val_loss: 10.9150 - val_mae: 2.4567\n",
            "processing fold # 3\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 17ms/step - loss: 576.3006 - mae: 22.2814 - val_loss: 481.4901 - val_mae: 19.5840\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 449.6844 - mae: 19.0540 - val_loss: 377.9883 - val_mae: 16.8366\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 313.0770 - mae: 15.8158 - val_loss: 263.5511 - val_mae: 13.5652\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 236.7134 - mae: 13.1029 - val_loss: 163.7289 - val_mae: 10.2425\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 155.3564 - mae: 10.0838 - val_loss: 103.2955 - val_mae: 8.0114\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 89.9051 - mae: 7.4060 - val_loss: 72.6571 - val_mae: 6.7132\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 57.4071 - mae: 5.7404 - val_loss: 54.9838 - val_mae: 5.6582\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 39.3737 - mae: 4.6295 - val_loss: 43.0706 - val_mae: 4.8035\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 27.4329 - mae: 4.0204 - val_loss: 35.2869 - val_mae: 4.1296\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 23.1484 - mae: 3.6107 - val_loss: 31.2977 - val_mae: 3.8235\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 28.9291 - mae: 3.6720 - val_loss: 28.4055 - val_mae: 3.5983\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 22.2371 - mae: 3.3907 - val_loss: 26.2817 - val_mae: 3.3886\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 18.4941 - mae: 3.1174 - val_loss: 25.2398 - val_mae: 3.2825\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 16.0484 - mae: 2.9255 - val_loss: 23.7074 - val_mae: 3.1628\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 16.5016 - mae: 2.9057 - val_loss: 22.8594 - val_mae: 3.0450\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 16.5436 - mae: 2.9560 - val_loss: 22.4683 - val_mae: 2.9778\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 13.6611 - mae: 2.7173 - val_loss: 21.1890 - val_mae: 2.9202\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.8902 - mae: 2.7326 - val_loss: 21.5767 - val_mae: 2.9467\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 14.5300 - mae: 2.7790 - val_loss: 20.6353 - val_mae: 2.8170\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 12.1951 - mae: 2.5436 - val_loss: 19.8190 - val_mae: 2.8048\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 12.4802 - mae: 2.5188 - val_loss: 19.8824 - val_mae: 2.7452\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.8417 - mae: 2.3105 - val_loss: 18.9687 - val_mae: 2.7179\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.3371 - mae: 2.2235 - val_loss: 18.8313 - val_mae: 2.6878\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.4669 - mae: 2.2063 - val_loss: 19.1470 - val_mae: 2.7193\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.7797 - mae: 2.4097 - val_loss: 18.3559 - val_mae: 2.7217\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.2767 - mae: 2.2296 - val_loss: 17.4946 - val_mae: 2.6361\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.1486 - mae: 2.2763 - val_loss: 17.8397 - val_mae: 2.6238\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.0494 - mae: 2.1110 - val_loss: 17.2669 - val_mae: 2.6101\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.1066 - mae: 2.3422 - val_loss: 17.7814 - val_mae: 2.6343\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.9377 - mae: 2.2084 - val_loss: 16.9384 - val_mae: 2.5745\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.7328 - mae: 2.0947 - val_loss: 17.8033 - val_mae: 2.7054\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.0624 - mae: 2.2395 - val_loss: 16.3279 - val_mae: 2.5741\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.5095 - mae: 2.0467 - val_loss: 16.4917 - val_mae: 2.6516\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.9954 - mae: 2.2584 - val_loss: 18.0815 - val_mae: 2.6583\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.6140 - mae: 2.1130 - val_loss: 16.7356 - val_mae: 2.5694\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.2175 - mae: 2.0746 - val_loss: 16.6874 - val_mae: 2.5783\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.9241 - mae: 2.1750 - val_loss: 16.3583 - val_mae: 2.5544\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.3440 - mae: 1.9332 - val_loss: 15.9041 - val_mae: 2.5495\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 6.8026 - mae: 1.9047 - val_loss: 16.4319 - val_mae: 2.5730\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.2284 - mae: 2.2013 - val_loss: 16.8316 - val_mae: 2.5809\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7506 - mae: 1.9707 - val_loss: 16.6935 - val_mae: 2.7062\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.6239 - mae: 1.8904 - val_loss: 16.0146 - val_mae: 2.5601\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.4277 - mae: 1.9552 - val_loss: 16.1787 - val_mae: 2.5250\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.8446 - mae: 1.9106 - val_loss: 14.7701 - val_mae: 2.5262\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.7475 - mae: 2.0112 - val_loss: 14.8748 - val_mae: 2.5070\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.1142 - mae: 2.0207 - val_loss: 15.0889 - val_mae: 2.4520\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.6882 - mae: 1.9882 - val_loss: 15.3542 - val_mae: 2.5314\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.4632 - mae: 1.8386 - val_loss: 15.1777 - val_mae: 2.4685\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.6186 - mae: 1.9106 - val_loss: 15.9131 - val_mae: 2.5349\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.1624 - mae: 1.8625 - val_loss: 15.2404 - val_mae: 2.4693\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.7252 - mae: 1.7754 - val_loss: 15.6810 - val_mae: 2.5556\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.1378 - mae: 1.7205 - val_loss: 15.7224 - val_mae: 2.5125\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.7286 - mae: 1.9015 - val_loss: 15.3949 - val_mae: 2.4920\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.5940 - mae: 2.1046 - val_loss: 15.2959 - val_mae: 2.5721\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.6889 - mae: 1.8513 - val_loss: 15.7017 - val_mae: 2.5595\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.9498 - mae: 1.8481 - val_loss: 14.7488 - val_mae: 2.4042\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.9511 - mae: 1.8177 - val_loss: 14.5206 - val_mae: 2.4103\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.9386 - mae: 1.8684 - val_loss: 14.2995 - val_mae: 2.3980\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.0496 - mae: 1.7977 - val_loss: 15.1739 - val_mae: 2.4815\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.5169 - mae: 1.8408 - val_loss: 16.0306 - val_mae: 2.5851\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.1530 - mae: 1.8465 - val_loss: 14.9845 - val_mae: 2.5079\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.4605 - mae: 1.9459 - val_loss: 14.9136 - val_mae: 2.4108\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0505 - mae: 1.6953 - val_loss: 14.8684 - val_mae: 2.4359\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7537 - mae: 1.9142 - val_loss: 14.8073 - val_mae: 2.4165\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.8646 - mae: 1.8219 - val_loss: 15.1243 - val_mae: 2.4760\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7014 - mae: 1.8349 - val_loss: 17.1273 - val_mae: 2.5729\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7325 - mae: 1.8863 - val_loss: 14.2385 - val_mae: 2.3969\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.3051 - mae: 1.6929 - val_loss: 14.7690 - val_mae: 2.4925\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1335 - mae: 1.6741 - val_loss: 15.8808 - val_mae: 2.5746\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7420 - mae: 1.6703 - val_loss: 15.3686 - val_mae: 2.5019\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.5090 - mae: 1.8352 - val_loss: 15.9261 - val_mae: 2.4623\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.5687 - mae: 1.7757 - val_loss: 15.0116 - val_mae: 2.4289\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.7388 - mae: 1.6580 - val_loss: 14.8527 - val_mae: 2.4145\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.5338 - mae: 1.7128 - val_loss: 14.6400 - val_mae: 2.4677\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.5054 - mae: 1.7334 - val_loss: 13.7960 - val_mae: 2.3709\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.4241 - mae: 1.7139 - val_loss: 14.7433 - val_mae: 2.4002\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.9560 - mae: 1.7270 - val_loss: 14.8544 - val_mae: 2.4161\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.3654 - mae: 1.7150 - val_loss: 13.5998 - val_mae: 2.4405\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.6581 - mae: 1.8225 - val_loss: 14.5001 - val_mae: 2.3588\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.2104 - mae: 1.7271 - val_loss: 14.5621 - val_mae: 2.4553\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.9201 - mae: 1.8180 - val_loss: 14.6146 - val_mae: 2.4858\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.9556 - mae: 1.8091 - val_loss: 16.7816 - val_mae: 2.5498\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 6.3638 - mae: 1.7993 - val_loss: 13.5594 - val_mae: 2.4121\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.9425 - mae: 1.7588 - val_loss: 14.9806 - val_mae: 2.4361\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.8139 - mae: 1.8511 - val_loss: 13.6276 - val_mae: 2.3382\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.8636 - mae: 1.6550 - val_loss: 13.6698 - val_mae: 2.4240\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.2801 - mae: 1.7733 - val_loss: 14.3493 - val_mae: 2.4307\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0525 - mae: 1.6527 - val_loss: 13.6202 - val_mae: 2.3496\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.9934 - mae: 1.6450 - val_loss: 14.2916 - val_mae: 2.3949\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.4253 - mae: 1.7236 - val_loss: 13.4221 - val_mae: 2.3505\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.0199 - mae: 1.6266 - val_loss: 13.8859 - val_mae: 2.3656\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1502 - mae: 1.7264 - val_loss: 14.2293 - val_mae: 2.3653\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.2696 - mae: 1.5151 - val_loss: 13.1419 - val_mae: 2.3382\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0052 - mae: 1.5106 - val_loss: 14.8249 - val_mae: 2.4390\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.2659 - mae: 1.6529 - val_loss: 13.5573 - val_mae: 2.3302\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.0646 - mae: 1.6862 - val_loss: 13.3505 - val_mae: 2.3356\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.7935 - mae: 1.6193 - val_loss: 13.3856 - val_mae: 2.3027\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.2588 - mae: 1.6927 - val_loss: 13.2579 - val_mae: 2.3045\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.2893 - mae: 1.5349 - val_loss: 14.1352 - val_mae: 2.4010\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.8035 - mae: 1.5771 - val_loss: 14.3253 - val_mae: 2.4078\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8796 - mae: 1.6123 - val_loss: 15.6485 - val_mae: 2.5701\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2347 - mae: 1.6070 - val_loss: 13.1883 - val_mae: 2.3060\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8093 - mae: 1.4634 - val_loss: 13.2039 - val_mae: 2.2767\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.7600 - mae: 1.7613 - val_loss: 13.7083 - val_mae: 2.3495\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.6502 - mae: 1.6147 - val_loss: 13.7838 - val_mae: 2.3666\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.6977 - mae: 1.6488 - val_loss: 13.0925 - val_mae: 2.2837\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8385 - mae: 1.4766 - val_loss: 13.5336 - val_mae: 2.3153\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.4176 - mae: 1.4390 - val_loss: 14.2472 - val_mae: 2.3795\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1090 - mae: 1.6748 - val_loss: 16.3935 - val_mae: 2.6474\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.8814 - mae: 1.5597 - val_loss: 14.6600 - val_mae: 2.4050\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.1133 - mae: 1.5752 - val_loss: 12.8123 - val_mae: 2.3234\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1530 - mae: 1.5370 - val_loss: 14.6917 - val_mae: 2.4300\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3526 - mae: 1.5404 - val_loss: 14.9150 - val_mae: 2.5362\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3038 - mae: 1.4950 - val_loss: 13.1209 - val_mae: 2.3232\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.8199 - mae: 1.4500 - val_loss: 14.0127 - val_mae: 2.4067\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3929 - mae: 1.4999 - val_loss: 12.9586 - val_mae: 2.3020\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.7660 - mae: 1.4958 - val_loss: 14.8713 - val_mae: 2.4222\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3695 - mae: 1.5261 - val_loss: 13.0972 - val_mae: 2.3267\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1698 - mae: 1.5166 - val_loss: 13.4313 - val_mae: 2.3213\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.9918 - mae: 1.5015 - val_loss: 14.0043 - val_mae: 2.3782\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7390 - mae: 1.4344 - val_loss: 13.3765 - val_mae: 2.3595\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.2131 - mae: 1.5115 - val_loss: 12.8672 - val_mae: 2.2938\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.9073 - mae: 1.4814 - val_loss: 14.3125 - val_mae: 2.4190\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.3283 - mae: 1.5611 - val_loss: 14.1739 - val_mae: 2.5585\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.2950 - mae: 1.5801 - val_loss: 15.7226 - val_mae: 2.5148\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8863 - mae: 1.4290 - val_loss: 13.7490 - val_mae: 2.3472\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1879 - mae: 1.4596 - val_loss: 13.2865 - val_mae: 2.3241\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8960 - mae: 1.4245 - val_loss: 13.5377 - val_mae: 2.3688\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5900 - mae: 1.4422 - val_loss: 14.0251 - val_mae: 2.3599\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.8980 - mae: 1.6022 - val_loss: 13.6295 - val_mae: 2.3713\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.4371 - mae: 1.4861 - val_loss: 13.7215 - val_mae: 2.3513\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.2150 - mae: 1.3454 - val_loss: 12.8539 - val_mae: 2.3388\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.0724 - mae: 1.4642 - val_loss: 12.3570 - val_mae: 2.2892\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7443 - mae: 1.3834 - val_loss: 14.0961 - val_mae: 2.4812\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.4822 - mae: 1.3678 - val_loss: 14.3205 - val_mae: 2.4394\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.2209 - mae: 1.5590 - val_loss: 12.9719 - val_mae: 2.3046\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5267 - mae: 1.3944 - val_loss: 14.0552 - val_mae: 2.4297\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.1603 - mae: 1.3484 - val_loss: 13.4182 - val_mae: 2.3363\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9479 - mae: 1.2988 - val_loss: 13.8503 - val_mae: 2.3700\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4751 - mae: 1.4120 - val_loss: 14.9406 - val_mae: 2.4979\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3643 - mae: 1.3651 - val_loss: 13.0197 - val_mae: 2.3545\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6689 - mae: 1.4235 - val_loss: 13.1635 - val_mae: 2.3952\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.5566 - mae: 1.4527 - val_loss: 13.5684 - val_mae: 2.3664\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.6201 - mae: 1.4165 - val_loss: 14.4177 - val_mae: 2.4402\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7908 - mae: 1.2368 - val_loss: 14.9910 - val_mae: 2.4833\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.0953 - mae: 1.3360 - val_loss: 13.8772 - val_mae: 2.4271\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7526 - mae: 1.4008 - val_loss: 14.1012 - val_mae: 2.4316\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.5887 - mae: 1.4854 - val_loss: 13.4431 - val_mae: 2.3635\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.4887 - mae: 1.4138 - val_loss: 12.9923 - val_mae: 2.3232\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.4630 - mae: 1.3465 - val_loss: 13.4447 - val_mae: 2.3550\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2434 - mae: 1.3722 - val_loss: 13.2241 - val_mae: 2.3476\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.7152 - mae: 1.4071 - val_loss: 12.5659 - val_mae: 2.3292\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.4982 - mae: 1.3999 - val_loss: 13.1024 - val_mae: 2.3224\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5370 - mae: 1.1846 - val_loss: 17.2243 - val_mae: 2.8040\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3396 - mae: 1.3832 - val_loss: 14.0751 - val_mae: 2.4174\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.1810 - mae: 1.3557 - val_loss: 12.4549 - val_mae: 2.2530\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0196 - mae: 1.2942 - val_loss: 12.9124 - val_mae: 2.3223\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.9395 - mae: 1.2908 - val_loss: 12.4153 - val_mae: 2.2623\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8457 - mae: 1.2602 - val_loss: 12.7179 - val_mae: 2.2809\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2216 - mae: 1.3908 - val_loss: 13.6147 - val_mae: 2.3734\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3394 - mae: 1.3588 - val_loss: 12.5213 - val_mae: 2.3125\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9588 - mae: 1.2893 - val_loss: 13.3192 - val_mae: 2.4228\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0278 - mae: 1.3102 - val_loss: 12.3370 - val_mae: 2.3338\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3378 - mae: 1.4078 - val_loss: 12.7015 - val_mae: 2.3022\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5682 - mae: 1.2065 - val_loss: 14.9295 - val_mae: 2.5918\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.9441 - mae: 1.3332 - val_loss: 13.5810 - val_mae: 2.3872\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7280 - mae: 1.1851 - val_loss: 12.9914 - val_mae: 2.3148\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.4507 - mae: 1.3785 - val_loss: 13.1787 - val_mae: 2.4246\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.2541 - mae: 1.3548 - val_loss: 12.0156 - val_mae: 2.2761\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7114 - mae: 1.2430 - val_loss: 13.5333 - val_mae: 2.3866\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.0545 - mae: 1.3410 - val_loss: 12.7902 - val_mae: 2.2735\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.5600 - mae: 1.2321 - val_loss: 14.9797 - val_mae: 2.5157\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.1504 - mae: 1.3207 - val_loss: 14.9436 - val_mae: 2.5763\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.0652 - mae: 1.3226 - val_loss: 12.8226 - val_mae: 2.3048\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8829 - mae: 1.2602 - val_loss: 13.8469 - val_mae: 2.3923\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3890 - mae: 1.1994 - val_loss: 12.6802 - val_mae: 2.2780\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4454 - mae: 1.1585 - val_loss: 12.4912 - val_mae: 2.2810\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6627 - mae: 1.2541 - val_loss: 12.9144 - val_mae: 2.3288\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.3248 - mae: 1.3269 - val_loss: 12.1305 - val_mae: 2.2566\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4358 - mae: 1.1633 - val_loss: 13.3945 - val_mae: 2.3510\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5758 - mae: 1.1973 - val_loss: 14.0100 - val_mae: 2.4336\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3327 - mae: 1.1569 - val_loss: 13.6075 - val_mae: 2.4604\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6941 - mae: 1.2469 - val_loss: 12.3534 - val_mae: 2.2819\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7729 - mae: 1.2885 - val_loss: 15.5339 - val_mae: 2.5374\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8337 - mae: 1.2725 - val_loss: 11.9618 - val_mae: 2.2549\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3123 - mae: 1.1920 - val_loss: 12.5840 - val_mae: 2.3061\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5365 - mae: 1.2181 - val_loss: 12.7068 - val_mae: 2.3209\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3541 - mae: 1.1535 - val_loss: 15.0824 - val_mae: 2.6109\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.9930 - mae: 1.3248 - val_loss: 13.1774 - val_mae: 2.3621\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1580 - mae: 1.1075 - val_loss: 13.8674 - val_mae: 2.4044\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3879 - mae: 1.1387 - val_loss: 12.8325 - val_mae: 2.4007\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.7647 - mae: 1.1731 - val_loss: 12.5276 - val_mae: 2.3116\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0839 - mae: 1.0539 - val_loss: 15.6787 - val_mae: 2.6189\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8874 - mae: 1.2744 - val_loss: 13.9055 - val_mae: 2.4917\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4209 - mae: 1.1564 - val_loss: 13.4112 - val_mae: 2.3793\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7017 - mae: 1.2586 - val_loss: 15.0023 - val_mae: 2.5588\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3309 - mae: 1.1578 - val_loss: 12.4477 - val_mae: 2.2832\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8857 - mae: 1.2829 - val_loss: 13.6693 - val_mae: 2.4158\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.0008 - mae: 1.3082 - val_loss: 11.9852 - val_mae: 2.2902\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5370 - mae: 1.1642 - val_loss: 12.5546 - val_mae: 2.2913\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2085 - mae: 1.0583 - val_loss: 13.1703 - val_mae: 2.3533\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.0398 - mae: 1.0689 - val_loss: 11.9986 - val_mae: 2.3267\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6817 - mae: 1.2741 - val_loss: 11.8347 - val_mae: 2.2044\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5447 - mae: 1.1903 - val_loss: 12.9476 - val_mae: 2.3387\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1730 - mae: 1.1317 - val_loss: 12.2853 - val_mae: 2.2694\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2467 - mae: 1.1041 - val_loss: 12.3187 - val_mae: 2.2867\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9902 - mae: 1.0499 - val_loss: 13.4166 - val_mae: 2.4056\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1013 - mae: 1.1194 - val_loss: 12.4350 - val_mae: 2.2986\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4355 - mae: 1.1656 - val_loss: 13.0048 - val_mae: 2.3513\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3633 - mae: 1.1623 - val_loss: 13.2666 - val_mae: 2.3640\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8834 - mae: 1.0100 - val_loss: 13.0023 - val_mae: 2.3419\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0598 - mae: 1.1012 - val_loss: 12.1357 - val_mae: 2.2820\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.4372 - mae: 1.1457 - val_loss: 13.1910 - val_mae: 2.3500\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.8561 - mae: 1.0417 - val_loss: 13.4291 - val_mae: 2.3896\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.8387 - mae: 1.0116 - val_loss: 12.3322 - val_mae: 2.3348\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1872 - mae: 1.1520 - val_loss: 11.7971 - val_mae: 2.2531\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6193 - mae: 0.9909 - val_loss: 13.8083 - val_mae: 2.4185\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1555 - mae: 1.0440 - val_loss: 12.3064 - val_mae: 2.3269\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0534 - mae: 1.0478 - val_loss: 12.2552 - val_mae: 2.2936\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.0800 - mae: 1.0747 - val_loss: 12.2884 - val_mae: 2.3286\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1459 - mae: 1.1101 - val_loss: 15.5090 - val_mae: 2.6111\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4564 - mae: 1.1841 - val_loss: 13.5970 - val_mae: 2.4549\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7951 - mae: 1.0038 - val_loss: 13.4735 - val_mae: 2.3580\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.8107 - mae: 0.9918 - val_loss: 15.0343 - val_mae: 2.6014\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9451 - mae: 1.0665 - val_loss: 14.1008 - val_mae: 2.4340\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1100 - mae: 1.0589 - val_loss: 13.4460 - val_mae: 2.3740\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5753 - mae: 0.9401 - val_loss: 13.9310 - val_mae: 2.4512\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.6711 - mae: 1.1969 - val_loss: 13.3588 - val_mae: 2.3839\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0908 - mae: 1.0526 - val_loss: 13.5546 - val_mae: 2.4122\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4579 - mae: 1.1851 - val_loss: 13.0020 - val_mae: 2.3477\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.8492 - mae: 0.9767 - val_loss: 12.1066 - val_mae: 2.3164\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9489 - mae: 1.0496 - val_loss: 13.3233 - val_mae: 2.3429\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8189 - mae: 0.9499 - val_loss: 13.2152 - val_mae: 2.3678\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.8235 - mae: 1.0435 - val_loss: 12.7834 - val_mae: 2.3543\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.8012 - mae: 0.9956 - val_loss: 12.7815 - val_mae: 2.3087\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0165 - mae: 1.0618 - val_loss: 12.6045 - val_mae: 2.3291\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6835 - mae: 0.9946 - val_loss: 14.4587 - val_mae: 2.5387\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.7886 - mae: 1.0346 - val_loss: 12.8525 - val_mae: 2.3633\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.8784 - mae: 1.0194 - val_loss: 13.8839 - val_mae: 2.4091\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7974 - mae: 0.9886 - val_loss: 12.6748 - val_mae: 2.2926\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1100 - mae: 1.1051 - val_loss: 13.6790 - val_mae: 2.3706\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1071 - mae: 1.0808 - val_loss: 13.4554 - val_mae: 2.3751\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.8933 - mae: 0.9760 - val_loss: 13.1566 - val_mae: 2.3131\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6777 - mae: 0.9604 - val_loss: 13.8928 - val_mae: 2.4081\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5465 - mae: 0.9472 - val_loss: 12.5970 - val_mae: 2.2903\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.5825 - mae: 0.9121 - val_loss: 13.5511 - val_mae: 2.3832\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7926 - mae: 1.0047 - val_loss: 15.5850 - val_mae: 2.6814\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8073 - mae: 1.0153 - val_loss: 12.7971 - val_mae: 2.3400\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5319 - mae: 0.9382 - val_loss: 12.2467 - val_mae: 2.2880\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7129 - mae: 1.0304 - val_loss: 14.1236 - val_mae: 2.4815\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6797 - mae: 0.9771 - val_loss: 13.3077 - val_mae: 2.3664\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8435 - mae: 0.9934 - val_loss: 14.0609 - val_mae: 2.4230\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9792 - mae: 1.0298 - val_loss: 12.6014 - val_mae: 2.2716\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7071 - mae: 0.9391 - val_loss: 12.7868 - val_mae: 2.3486\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5766 - mae: 0.9648 - val_loss: 14.0019 - val_mae: 2.4576\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9816 - mae: 1.0442 - val_loss: 13.2514 - val_mae: 2.3689\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4606 - mae: 0.9182 - val_loss: 14.1652 - val_mae: 2.4684\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9119 - mae: 1.0377 - val_loss: 13.4181 - val_mae: 2.4426\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8644 - mae: 1.0173 - val_loss: 13.0460 - val_mae: 2.3301\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9546 - mae: 1.0191 - val_loss: 13.5438 - val_mae: 2.3968\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5772 - mae: 0.9359 - val_loss: 15.2404 - val_mae: 2.5213\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.7013 - mae: 0.9959 - val_loss: 13.3999 - val_mae: 2.3874\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6944 - mae: 0.9748 - val_loss: 13.6035 - val_mae: 2.4154\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.6207 - mae: 0.9775 - val_loss: 12.8640 - val_mae: 2.3384\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.8121 - mae: 0.9899 - val_loss: 13.8316 - val_mae: 2.4951\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.4249 - mae: 0.9040 - val_loss: 13.2604 - val_mae: 2.3986\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7657 - mae: 0.9702 - val_loss: 15.4877 - val_mae: 2.5542\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5927 - mae: 0.9811 - val_loss: 14.5383 - val_mae: 2.4693\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.6557 - mae: 0.9566 - val_loss: 13.8141 - val_mae: 2.4829\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5343 - mae: 0.9247 - val_loss: 15.5410 - val_mae: 2.6122\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5322 - mae: 0.9344 - val_loss: 13.6160 - val_mae: 2.4442\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.6943 - mae: 0.9718 - val_loss: 12.9782 - val_mae: 2.3455\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5034 - mae: 0.9008 - val_loss: 12.9090 - val_mae: 2.3199\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.8055 - mae: 0.9855 - val_loss: 14.7257 - val_mae: 2.5250\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0913 - mae: 1.0843 - val_loss: 12.5493 - val_mae: 2.3187\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5548 - mae: 0.9644 - val_loss: 12.6542 - val_mae: 2.3059\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5647 - mae: 0.9119 - val_loss: 12.3815 - val_mae: 2.2473\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.3585 - mae: 0.8473 - val_loss: 12.6095 - val_mae: 2.3149\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3740 - mae: 0.9064 - val_loss: 14.6865 - val_mae: 2.5071\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5298 - mae: 0.9109 - val_loss: 13.4065 - val_mae: 2.3626\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.3135 - mae: 0.8546 - val_loss: 14.2371 - val_mae: 2.4815\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.2004 - mae: 0.8149 - val_loss: 14.8352 - val_mae: 2.4987\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.3903 - mae: 0.8753 - val_loss: 14.5506 - val_mae: 2.4833\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.2839 - mae: 0.8374 - val_loss: 14.0491 - val_mae: 2.4353\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.3745 - mae: 0.8632 - val_loss: 12.2936 - val_mae: 2.3270\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0901 - mae: 1.0956 - val_loss: 12.8044 - val_mae: 2.3446\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5168 - mae: 0.8989 - val_loss: 13.6680 - val_mae: 2.3794\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.2169 - mae: 0.7918 - val_loss: 13.2115 - val_mae: 2.3821\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5023 - mae: 0.8828 - val_loss: 14.0060 - val_mae: 2.4692\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6634 - mae: 0.9726 - val_loss: 12.4578 - val_mae: 2.3595\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3571 - mae: 0.8701 - val_loss: 13.9663 - val_mae: 2.4670\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4129 - mae: 0.8857 - val_loss: 15.3171 - val_mae: 2.5662\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3775 - mae: 0.8866 - val_loss: 12.9574 - val_mae: 2.4492\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.4775 - mae: 0.8620 - val_loss: 12.9607 - val_mae: 2.3860\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.3468 - mae: 0.8693 - val_loss: 13.4002 - val_mae: 2.3900\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.2757 - mae: 0.8486 - val_loss: 13.4086 - val_mae: 2.3506\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.3461 - mae: 0.8955 - val_loss: 15.5344 - val_mae: 2.5644\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5894 - mae: 0.9623 - val_loss: 14.4574 - val_mae: 2.4884\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3401 - mae: 0.8642 - val_loss: 12.7141 - val_mae: 2.2681\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3169 - mae: 0.8689 - val_loss: 12.4712 - val_mae: 2.3130\n",
            "processing fold # 4\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 15ms/step - loss: 555.5380 - mae: 21.9291 - val_loss: 578.1956 - val_mae: 22.1438\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 461.8185 - mae: 19.6868 - val_loss: 476.2312 - val_mae: 19.8509\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 348.2006 - mae: 16.9455 - val_loss: 365.7728 - val_mae: 16.9968\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 266.5794 - mae: 14.3453 - val_loss: 245.6385 - val_mae: 13.1681\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 149.7993 - mae: 10.0427 - val_loss: 158.5740 - val_mae: 9.6936\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 75.2988 - mae: 6.9674 - val_loss: 107.8300 - val_mae: 7.5840\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 64.5201 - mae: 6.1127 - val_loss: 77.6501 - val_mae: 6.2211\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 36.8994 - mae: 4.7398 - val_loss: 62.3542 - val_mae: 5.3853\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 34.3138 - mae: 4.1424 - val_loss: 49.9720 - val_mae: 4.7785\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 32.1500 - mae: 3.8363 - val_loss: 45.0981 - val_mae: 4.3885\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 29.1775 - mae: 3.6583 - val_loss: 42.3147 - val_mae: 4.1493\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 23.7664 - mae: 3.2104 - val_loss: 38.0548 - val_mae: 4.0067\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 25.7062 - mae: 3.2972 - val_loss: 36.8032 - val_mae: 3.8327\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.0694 - mae: 2.7894 - val_loss: 32.3840 - val_mae: 3.6722\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 13.0783 - mae: 2.6478 - val_loss: 29.6796 - val_mae: 3.5874\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.2230 - mae: 3.0167 - val_loss: 29.3769 - val_mae: 3.5006\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 16.2113 - mae: 2.6625 - val_loss: 28.4383 - val_mae: 3.3920\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 15.6911 - mae: 2.6176 - val_loss: 26.2636 - val_mae: 3.4033\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 11.9318 - mae: 2.3625 - val_loss: 24.3243 - val_mae: 3.2389\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 12.8911 - mae: 2.3995 - val_loss: 24.4347 - val_mae: 3.1845\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 11.9026 - mae: 2.4524 - val_loss: 22.0252 - val_mae: 3.0801\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.6077 - mae: 2.2531 - val_loss: 22.1332 - val_mae: 3.1154\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 11.7050 - mae: 2.3697 - val_loss: 20.6659 - val_mae: 3.0945\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 15.0480 - mae: 2.5325 - val_loss: 22.1453 - val_mae: 3.1407\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 13.3839 - mae: 2.3129 - val_loss: 20.1266 - val_mae: 3.0654\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 12.9320 - mae: 2.4141 - val_loss: 19.5429 - val_mae: 2.9876\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.9624 - mae: 2.1441 - val_loss: 20.6203 - val_mae: 3.0702\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 11.0066 - mae: 2.2202 - val_loss: 17.7130 - val_mae: 2.8673\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.5215 - mae: 2.2457 - val_loss: 17.9168 - val_mae: 2.9464\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.6459 - mae: 2.1656 - val_loss: 17.4057 - val_mae: 2.8903\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.7974 - mae: 2.1536 - val_loss: 15.8748 - val_mae: 2.8336\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 11.4362 - mae: 2.3024 - val_loss: 16.9100 - val_mae: 2.8990\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.4040 - mae: 2.1539 - val_loss: 16.8393 - val_mae: 2.8830\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.8104 - mae: 2.0847 - val_loss: 16.3647 - val_mae: 2.8704\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.2579 - mae: 2.1080 - val_loss: 15.2030 - val_mae: 2.7761\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 9.1832 - mae: 2.0179 - val_loss: 15.2668 - val_mae: 2.8043\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.2390 - mae: 2.0578 - val_loss: 14.5393 - val_mae: 2.7307\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 11.3315 - mae: 2.1839 - val_loss: 14.7547 - val_mae: 2.7571\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.0536 - mae: 2.1304 - val_loss: 14.3748 - val_mae: 2.7320\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.4271 - mae: 2.0930 - val_loss: 15.1025 - val_mae: 2.8305\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.5098 - mae: 2.3102 - val_loss: 14.4577 - val_mae: 2.7453\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 7.9333 - mae: 2.0054 - val_loss: 14.0566 - val_mae: 2.7411\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.6280 - mae: 2.0889 - val_loss: 13.8776 - val_mae: 2.7027\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.6058 - mae: 1.9795 - val_loss: 14.0553 - val_mae: 2.7347\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.5486 - mae: 2.2582 - val_loss: 14.5491 - val_mae: 2.7628\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.7989 - mae: 1.9593 - val_loss: 13.3686 - val_mae: 2.6608\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.8837 - mae: 2.1356 - val_loss: 14.0367 - val_mae: 2.7423\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7711 - mae: 1.8740 - val_loss: 12.9547 - val_mae: 2.6233\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.2342 - mae: 2.0350 - val_loss: 13.4926 - val_mae: 2.7012\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.6528 - mae: 2.0609 - val_loss: 12.9744 - val_mae: 2.6224\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.6580 - mae: 2.0241 - val_loss: 13.2721 - val_mae: 2.6383\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.0699 - mae: 1.7500 - val_loss: 12.7987 - val_mae: 2.5932\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.7023 - mae: 1.9853 - val_loss: 13.1634 - val_mae: 2.6191\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 10.9173 - mae: 2.0723 - val_loss: 12.6924 - val_mae: 2.5843\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.3387 - mae: 1.9866 - val_loss: 12.7704 - val_mae: 2.6037\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.1753 - mae: 1.8902 - val_loss: 14.4875 - val_mae: 2.7724\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.7286 - mae: 1.8557 - val_loss: 12.0386 - val_mae: 2.5129\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.8847 - mae: 1.8190 - val_loss: 12.4686 - val_mae: 2.5673\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 8.6232 - mae: 2.0216 - val_loss: 13.1888 - val_mae: 2.6898\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.8206 - mae: 1.6780 - val_loss: 12.4884 - val_mae: 2.5193\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.3922 - mae: 1.9336 - val_loss: 12.1594 - val_mae: 2.4769\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.1092 - mae: 1.8637 - val_loss: 12.1397 - val_mae: 2.4984\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 8.9770 - mae: 2.0313 - val_loss: 12.6359 - val_mae: 2.5954\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.3175 - mae: 1.8308 - val_loss: 12.1368 - val_mae: 2.5556\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.5226 - mae: 1.8670 - val_loss: 11.7919 - val_mae: 2.4907\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 6.4246 - mae: 1.8022 - val_loss: 11.7529 - val_mae: 2.4942\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 8.3859 - mae: 1.9377 - val_loss: 12.0237 - val_mae: 2.5193\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.0082 - mae: 1.7583 - val_loss: 11.8389 - val_mae: 2.4875\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.5942 - mae: 1.6959 - val_loss: 11.6019 - val_mae: 2.4426\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.4972 - mae: 1.9044 - val_loss: 11.9610 - val_mae: 2.5243\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.7854 - mae: 1.8044 - val_loss: 11.7590 - val_mae: 2.5009\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.1146 - mae: 1.8196 - val_loss: 12.7403 - val_mae: 2.5929\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.8424 - mae: 1.8465 - val_loss: 12.6394 - val_mae: 2.6025\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.4031 - mae: 1.8197 - val_loss: 11.7697 - val_mae: 2.5083\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 7.3097 - mae: 1.8233 - val_loss: 13.1039 - val_mae: 2.7246\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 7.8181 - mae: 1.8164 - val_loss: 11.5731 - val_mae: 2.4784\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.5504 - mae: 1.6168 - val_loss: 12.7860 - val_mae: 2.6681\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.6237 - mae: 1.7761 - val_loss: 12.9388 - val_mae: 2.6597\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.7480 - mae: 1.6900 - val_loss: 11.8315 - val_mae: 2.5028\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.1981 - mae: 1.7912 - val_loss: 11.6691 - val_mae: 2.4499\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.4993 - mae: 1.5992 - val_loss: 11.8641 - val_mae: 2.4448\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.5749 - mae: 1.9300 - val_loss: 11.7533 - val_mae: 2.4970\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.1445 - mae: 1.7102 - val_loss: 11.4955 - val_mae: 2.4397\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.1655 - mae: 1.6632 - val_loss: 12.2385 - val_mae: 2.5296\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.9737 - mae: 1.7369 - val_loss: 11.5550 - val_mae: 2.5029\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.5905 - mae: 1.6643 - val_loss: 11.4640 - val_mae: 2.4710\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.6706 - mae: 1.5248 - val_loss: 11.7349 - val_mae: 2.4782\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.4374 - mae: 1.6819 - val_loss: 11.3728 - val_mae: 2.4534\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.0415 - mae: 1.8544 - val_loss: 11.6073 - val_mae: 2.4905\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.6573 - mae: 1.6417 - val_loss: 11.7151 - val_mae: 2.4923\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.2355 - mae: 1.5444 - val_loss: 11.6419 - val_mae: 2.4569\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.4882 - mae: 1.6023 - val_loss: 12.5785 - val_mae: 2.6289\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.1360 - mae: 1.5955 - val_loss: 12.0591 - val_mae: 2.4752\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.0031 - mae: 1.8581 - val_loss: 11.3903 - val_mae: 2.4605\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.2863 - mae: 1.7020 - val_loss: 11.8738 - val_mae: 2.5539\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.1597 - mae: 1.5787 - val_loss: 11.4149 - val_mae: 2.4637\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.4697 - mae: 1.6266 - val_loss: 11.9791 - val_mae: 2.5627\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.0644 - mae: 1.6203 - val_loss: 11.5674 - val_mae: 2.5164\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.6815 - mae: 1.4929 - val_loss: 11.7512 - val_mae: 2.5174\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.8857 - mae: 1.6393 - val_loss: 11.4645 - val_mae: 2.5105\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.2756 - mae: 1.6888 - val_loss: 12.1059 - val_mae: 2.5521\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.1734 - mae: 1.5585 - val_loss: 11.2772 - val_mae: 2.4756\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 6.6818 - mae: 1.7081 - val_loss: 11.2992 - val_mae: 2.4782\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 6.0911 - mae: 1.6433 - val_loss: 11.2206 - val_mae: 2.4352\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 7.6151 - mae: 1.7488 - val_loss: 11.2959 - val_mae: 2.4515\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.2084 - mae: 1.6775 - val_loss: 11.4811 - val_mae: 2.4854\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.8622 - mae: 1.6693 - val_loss: 11.6098 - val_mae: 2.5221\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.3507 - mae: 1.5610 - val_loss: 11.7502 - val_mae: 2.5463\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.7689 - mae: 1.6386 - val_loss: 11.2869 - val_mae: 2.4735\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 7.2838 - mae: 1.5891 - val_loss: 11.7052 - val_mae: 2.5359\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.8182 - mae: 1.7314 - val_loss: 11.5094 - val_mae: 2.5066\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.6655 - mae: 1.3661 - val_loss: 11.8947 - val_mae: 2.5473\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 6.1408 - mae: 1.5956 - val_loss: 12.1878 - val_mae: 2.6149\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.4850 - mae: 1.5749 - val_loss: 11.2190 - val_mae: 2.4516\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.6447 - mae: 1.6501 - val_loss: 11.7812 - val_mae: 2.5126\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.6918 - mae: 1.4947 - val_loss: 11.5465 - val_mae: 2.4706\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.1673 - mae: 1.4564 - val_loss: 12.0183 - val_mae: 2.5399\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.7996 - mae: 1.5780 - val_loss: 11.4681 - val_mae: 2.4839\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.3684 - mae: 1.5269 - val_loss: 12.5883 - val_mae: 2.6456\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.3626 - mae: 1.6007 - val_loss: 11.5472 - val_mae: 2.5238\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.5864 - mae: 1.4803 - val_loss: 11.5195 - val_mae: 2.5237\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 5.6031 - mae: 1.4759 - val_loss: 12.3911 - val_mae: 2.6119\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.1162 - mae: 1.5505 - val_loss: 12.1687 - val_mae: 2.5747\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.0106 - mae: 1.5293 - val_loss: 12.4024 - val_mae: 2.6068\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.7169 - mae: 1.6658 - val_loss: 11.2405 - val_mae: 2.4718\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.2293 - mae: 1.4513 - val_loss: 11.7728 - val_mae: 2.5517\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.4590 - mae: 1.5114 - val_loss: 11.4684 - val_mae: 2.4813\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.2293 - mae: 1.4779 - val_loss: 11.4838 - val_mae: 2.5121\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.0948 - mae: 1.5393 - val_loss: 11.7769 - val_mae: 2.4938\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.0540 - mae: 1.6044 - val_loss: 11.8107 - val_mae: 2.5109\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.8174 - mae: 1.4640 - val_loss: 11.9535 - val_mae: 2.5627\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.5405 - mae: 1.5279 - val_loss: 13.0065 - val_mae: 2.6821\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.8253 - mae: 1.5249 - val_loss: 11.7758 - val_mae: 2.5477\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.3115 - mae: 1.4331 - val_loss: 11.5837 - val_mae: 2.5122\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.6834 - mae: 1.4511 - val_loss: 11.9055 - val_mae: 2.5507\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.4526 - mae: 1.4084 - val_loss: 12.0941 - val_mae: 2.5746\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.3791 - mae: 1.4579 - val_loss: 11.8988 - val_mae: 2.5369\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.2003 - mae: 1.4926 - val_loss: 11.7742 - val_mae: 2.5472\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3619 - mae: 1.2732 - val_loss: 11.9261 - val_mae: 2.5556\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.3388 - mae: 1.4246 - val_loss: 12.0031 - val_mae: 2.5751\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.0696 - mae: 1.3354 - val_loss: 11.6066 - val_mae: 2.5141\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.8287 - mae: 1.4739 - val_loss: 11.7945 - val_mae: 2.5560\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.3191 - mae: 1.4406 - val_loss: 11.8023 - val_mae: 2.5492\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.7477 - mae: 1.3688 - val_loss: 11.6862 - val_mae: 2.5153\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.5559 - mae: 1.3045 - val_loss: 14.2045 - val_mae: 2.8027\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.9757 - mae: 1.5372 - val_loss: 12.5916 - val_mae: 2.6481\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1152 - mae: 1.4199 - val_loss: 11.9139 - val_mae: 2.5313\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.3394 - mae: 1.2942 - val_loss: 12.0372 - val_mae: 2.5695\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.9710 - mae: 1.3329 - val_loss: 12.4764 - val_mae: 2.6176\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.6169 - mae: 1.4311 - val_loss: 12.2842 - val_mae: 2.5580\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1995 - mae: 1.3325 - val_loss: 11.8546 - val_mae: 2.5265\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.5780 - mae: 1.3040 - val_loss: 12.3698 - val_mae: 2.6532\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3519 - mae: 1.2594 - val_loss: 12.0288 - val_mae: 2.5502\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3911 - mae: 1.2684 - val_loss: 12.0248 - val_mae: 2.5561\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.7224 - mae: 1.4397 - val_loss: 12.6528 - val_mae: 2.5996\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 3.2772 - mae: 1.3496 - val_loss: 12.8006 - val_mae: 2.6349\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.8781 - mae: 1.4745 - val_loss: 12.1901 - val_mae: 2.5579\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4.9709 - mae: 1.4713 - val_loss: 12.5002 - val_mae: 2.5763\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.8417 - mae: 1.3030 - val_loss: 12.8976 - val_mae: 2.6705\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.4999 - mae: 1.3585 - val_loss: 12.6455 - val_mae: 2.6117\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.7872 - mae: 1.3458 - val_loss: 12.7917 - val_mae: 2.6153\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.8063 - mae: 1.2957 - val_loss: 11.9028 - val_mae: 2.5276\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.4795 - mae: 1.4221 - val_loss: 12.1622 - val_mae: 2.5544\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.9134 - mae: 1.3491 - val_loss: 12.7107 - val_mae: 2.6414\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.4942 - mae: 1.3260 - val_loss: 12.7504 - val_mae: 2.6469\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.5628 - mae: 1.4555 - val_loss: 12.6339 - val_mae: 2.6511\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1986 - mae: 1.3819 - val_loss: 12.0972 - val_mae: 2.5346\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.9907 - mae: 1.2074 - val_loss: 12.5757 - val_mae: 2.5998\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.8463 - mae: 1.4013 - val_loss: 12.0935 - val_mae: 2.5324\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 4.1977 - mae: 1.3139 - val_loss: 12.5847 - val_mae: 2.5930\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.5998 - mae: 1.2640 - val_loss: 13.2847 - val_mae: 2.6749\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.6787 - mae: 1.4038 - val_loss: 12.4691 - val_mae: 2.5840\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.0040 - mae: 1.2983 - val_loss: 13.2146 - val_mae: 2.6555\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.3907 - mae: 1.2916 - val_loss: 13.0933 - val_mae: 2.6697\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5.2387 - mae: 1.4517 - val_loss: 13.9234 - val_mae: 2.6988\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.0558 - mae: 1.2377 - val_loss: 13.8795 - val_mae: 2.7077\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.8593 - mae: 1.3073 - val_loss: 12.4648 - val_mae: 2.5709\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.1573 - mae: 1.2168 - val_loss: 12.3403 - val_mae: 2.5611\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.4505 - mae: 1.3049 - val_loss: 13.5918 - val_mae: 2.6583\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.7053 - mae: 1.2836 - val_loss: 12.9448 - val_mae: 2.6102\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7975 - mae: 1.1835 - val_loss: 13.1559 - val_mae: 2.6257\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.4278 - mae: 1.2530 - val_loss: 15.4580 - val_mae: 2.8154\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.1432 - mae: 1.5423 - val_loss: 12.8495 - val_mae: 2.6002\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.7859 - mae: 1.2054 - val_loss: 12.8308 - val_mae: 2.6113\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.2008 - mae: 1.2148 - val_loss: 12.6540 - val_mae: 2.5742\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.2159 - mae: 1.2215 - val_loss: 12.6652 - val_mae: 2.5635\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3814 - mae: 1.2425 - val_loss: 12.6850 - val_mae: 2.5770\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.6290 - mae: 1.2598 - val_loss: 13.1784 - val_mae: 2.6118\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.9646 - mae: 1.2767 - val_loss: 13.0439 - val_mae: 2.6069\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.6300 - mae: 1.1965 - val_loss: 13.4879 - val_mae: 2.6360\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.9965 - mae: 1.3104 - val_loss: 14.0459 - val_mae: 2.6671\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.1366 - mae: 1.2498 - val_loss: 13.6100 - val_mae: 2.7084\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.7544 - mae: 1.3603 - val_loss: 12.9884 - val_mae: 2.6850\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.6500 - mae: 1.3345 - val_loss: 13.9782 - val_mae: 2.6992\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.9172 - mae: 1.2277 - val_loss: 12.7568 - val_mae: 2.5856\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.1224 - mae: 1.1863 - val_loss: 13.7868 - val_mae: 2.6637\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.2836 - mae: 1.2428 - val_loss: 13.0985 - val_mae: 2.6362\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.1031 - mae: 1.1571 - val_loss: 12.9014 - val_mae: 2.6137\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.1285 - mae: 1.3455 - val_loss: 13.2113 - val_mae: 2.5925\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.4455 - mae: 1.1930 - val_loss: 14.6236 - val_mae: 2.7992\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.9206 - mae: 1.1777 - val_loss: 13.6073 - val_mae: 2.6546\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.2356 - mae: 1.1470 - val_loss: 16.3330 - val_mae: 2.9371\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.5014 - mae: 1.3093 - val_loss: 13.5473 - val_mae: 2.6721\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.2091 - mae: 1.1842 - val_loss: 13.8456 - val_mae: 2.6362\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6807 - mae: 1.1802 - val_loss: 13.7755 - val_mae: 2.6756\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3965 - mae: 1.2744 - val_loss: 14.1269 - val_mae: 2.6800\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.1742 - mae: 1.2033 - val_loss: 13.5051 - val_mae: 2.6200\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 3.2719 - mae: 1.1520 - val_loss: 14.8291 - val_mae: 2.7583\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.6256 - mae: 1.1463 - val_loss: 13.9442 - val_mae: 2.6896\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3846 - mae: 1.0534 - val_loss: 13.7906 - val_mae: 2.6993\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7604 - mae: 1.1682 - val_loss: 13.4746 - val_mae: 2.6328\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.0286 - mae: 1.1854 - val_loss: 14.8179 - val_mae: 2.8187\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.6433 - mae: 1.1189 - val_loss: 14.0776 - val_mae: 2.6848\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.8954 - mae: 1.1919 - val_loss: 13.9825 - val_mae: 2.7128\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.0158 - mae: 1.1414 - val_loss: 13.4435 - val_mae: 2.6473\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.8965 - mae: 1.2197 - val_loss: 13.8412 - val_mae: 2.6637\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.3121 - mae: 1.0835 - val_loss: 16.0810 - val_mae: 2.8490\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.0641 - mae: 1.2511 - val_loss: 14.2673 - val_mae: 2.6972\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.7583 - mae: 1.1354 - val_loss: 16.5419 - val_mae: 2.9537\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.0485 - mae: 1.1437 - val_loss: 15.2414 - val_mae: 2.7357\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.1885 - mae: 1.2165 - val_loss: 14.3185 - val_mae: 2.6521\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.8677 - mae: 1.1296 - val_loss: 14.3301 - val_mae: 2.7040\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.6496 - mae: 1.1103 - val_loss: 14.6040 - val_mae: 2.7198\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8046 - mae: 1.1035 - val_loss: 14.8954 - val_mae: 2.7359\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7603 - mae: 1.0669 - val_loss: 14.3727 - val_mae: 2.6705\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5427 - mae: 1.0796 - val_loss: 14.6275 - val_mae: 2.6798\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.0626 - mae: 1.1933 - val_loss: 13.7477 - val_mae: 2.6457\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4879 - mae: 1.1438 - val_loss: 14.5489 - val_mae: 2.7314\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9789 - mae: 1.2202 - val_loss: 16.9687 - val_mae: 2.9661\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.9580 - mae: 1.2914 - val_loss: 14.3666 - val_mae: 2.7273\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5178 - mae: 1.1030 - val_loss: 15.2904 - val_mae: 2.7822\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3102 - mae: 1.1881 - val_loss: 15.1901 - val_mae: 2.7591\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.3012 - mae: 1.1718 - val_loss: 13.8729 - val_mae: 2.6542\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4637 - mae: 1.0917 - val_loss: 14.8651 - val_mae: 2.7192\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2061 - mae: 1.0683 - val_loss: 14.2854 - val_mae: 2.7039\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.8180 - mae: 1.1354 - val_loss: 15.2564 - val_mae: 2.7648\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2465 - mae: 1.0762 - val_loss: 15.5302 - val_mae: 2.7639\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 2.2684 - mae: 0.9996 - val_loss: 14.7152 - val_mae: 2.7520\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.7379 - mae: 1.0992 - val_loss: 15.0165 - val_mae: 2.7300\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.8530 - mae: 1.1534 - val_loss: 14.3021 - val_mae: 2.6786\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.9216 - mae: 1.1116 - val_loss: 14.8129 - val_mae: 2.7768\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.2315 - mae: 1.1868 - val_loss: 15.4149 - val_mae: 2.7458\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.6808 - mae: 1.1207 - val_loss: 15.5297 - val_mae: 2.7743\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.1588 - mae: 1.1366 - val_loss: 15.3230 - val_mae: 2.7873\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4383 - mae: 1.1102 - val_loss: 14.8209 - val_mae: 2.7549\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.7340 - mae: 1.0796 - val_loss: 14.8407 - val_mae: 2.7126\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5184 - mae: 1.1322 - val_loss: 15.1281 - val_mae: 2.7525\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.7562 - mae: 1.1323 - val_loss: 15.4476 - val_mae: 2.7564\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 2.2261 - mae: 1.0059 - val_loss: 14.9614 - val_mae: 2.7364\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3042 - mae: 1.0488 - val_loss: 16.4366 - val_mae: 2.8242\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9679 - mae: 1.1120 - val_loss: 16.4241 - val_mae: 2.8090\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4908 - mae: 1.0651 - val_loss: 17.8312 - val_mae: 2.9884\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.8226 - mae: 1.1890 - val_loss: 15.6953 - val_mae: 2.8090\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.7248 - mae: 1.0963 - val_loss: 17.3709 - val_mae: 2.9955\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.6600 - mae: 1.1260 - val_loss: 15.2695 - val_mae: 2.7817\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2949 - mae: 1.0600 - val_loss: 15.6255 - val_mae: 2.7905\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4357 - mae: 1.0878 - val_loss: 15.1455 - val_mae: 2.7335\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.7604 - mae: 1.1296 - val_loss: 16.0931 - val_mae: 2.8306\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1484 - mae: 1.0294 - val_loss: 16.5114 - val_mae: 2.8095\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.6544 - mae: 1.1209 - val_loss: 17.5283 - val_mae: 2.8811\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.9099 - mae: 1.1601 - val_loss: 14.8507 - val_mae: 2.7748\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.5680 - mae: 1.1372 - val_loss: 14.9586 - val_mae: 2.7330\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1995 - mae: 0.9933 - val_loss: 16.0864 - val_mae: 2.8027\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.5369 - mae: 1.1081 - val_loss: 15.3513 - val_mae: 2.7175\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4550 - mae: 1.0627 - val_loss: 15.7147 - val_mae: 2.7554\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.2956 - mae: 1.0278 - val_loss: 16.0562 - val_mae: 2.8243\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4824 - mae: 1.0331 - val_loss: 15.5754 - val_mae: 2.8150\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.6764 - mae: 1.0565 - val_loss: 15.1822 - val_mae: 2.7381\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.7656 - mae: 1.1519 - val_loss: 15.8908 - val_mae: 2.7942\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.3977 - mae: 1.0555 - val_loss: 15.6199 - val_mae: 2.7471\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1512 - mae: 1.0121 - val_loss: 17.9770 - val_mae: 3.0201\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0484 - mae: 1.0318 - val_loss: 15.7065 - val_mae: 2.7941\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0664 - mae: 1.0104 - val_loss: 17.3665 - val_mae: 2.9123\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1827 - mae: 0.9704 - val_loss: 16.1881 - val_mae: 2.7980\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.0140 - mae: 1.1490 - val_loss: 16.8179 - val_mae: 2.8288\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4400 - mae: 1.0706 - val_loss: 15.6089 - val_mae: 2.7824\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.5103 - mae: 1.0624 - val_loss: 17.6036 - val_mae: 2.8697\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4063 - mae: 1.0752 - val_loss: 17.8998 - val_mae: 3.0293\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.0100 - mae: 0.9985 - val_loss: 16.1448 - val_mae: 2.7904\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1443 - mae: 0.9945 - val_loss: 16.7688 - val_mae: 2.8171\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1413 - mae: 1.0146 - val_loss: 16.2168 - val_mae: 2.8329\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9575 - mae: 0.9845 - val_loss: 16.4070 - val_mae: 2.8160\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.2100 - mae: 1.0690 - val_loss: 18.0941 - val_mae: 2.8861\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4678 - mae: 1.0898 - val_loss: 16.0053 - val_mae: 2.7801\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.9917 - mae: 0.9824 - val_loss: 15.8739 - val_mae: 2.8596\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1492 - mae: 1.0065 - val_loss: 15.8258 - val_mae: 2.7836\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4894 - mae: 0.9916 - val_loss: 16.6803 - val_mae: 2.9427\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.1021 - mae: 1.0378 - val_loss: 16.5838 - val_mae: 2.8066\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.1535 - mae: 1.0146 - val_loss: 16.0780 - val_mae: 2.8151\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.1548 - mae: 0.9848 - val_loss: 18.1231 - val_mae: 2.9170\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.4581 - mae: 1.0502 - val_loss: 17.3428 - val_mae: 2.8937\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9606 - mae: 0.9139 - val_loss: 16.6459 - val_mae: 2.8435\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.1913 - mae: 1.0089 - val_loss: 16.5593 - val_mae: 2.8164\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0624 - mae: 0.9089 - val_loss: 17.1323 - val_mae: 2.8379\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3216 - mae: 1.0238 - val_loss: 17.0335 - val_mae: 2.8490\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.3382 - mae: 1.0150 - val_loss: 16.4992 - val_mae: 2.8098\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.7933 - mae: 0.9416 - val_loss: 18.9909 - val_mae: 2.9538\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.1468 - mae: 1.0246 - val_loss: 18.8366 - val_mae: 3.0019\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 2.4742 - mae: 1.0692 - val_loss: 16.8562 - val_mae: 2.8259\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.8827 - mae: 0.9100 - val_loss: 16.1428 - val_mae: 2.7937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzNowPA-yIOM"
      },
      "source": [
        "### 학습 커브 가시화\n",
        "\n",
        "교차 검증이 수행되기 때문에, 매 에포크마다 mae를 산출하기위해 각 교차검증 시 해당하는 에포크의 mae을 모두 더해 평균을 내서 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddwbjCQBaIgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e6243a15-70be-4246-9602-6a3a3d91ab2a"
      },
      "source": [
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history, 'r', label='aver_mae')\n",
        "plt.title('MAE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIxkhw4A3G-m"
      },
      "source": [
        "지수 이동 평균으로 곡선을 부드럽게 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YIJ9ZCnaKm_"
      },
      "source": [
        "def smooth_curve(points, factor=1.01):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1-factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04PwvAeL1PXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "a1f3e059-d403-4b49-88ed-b601ff15aad7"
      },
      "source": [
        "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
        "\n",
        "plt.plot(range(1, len(smooth_mae_history)+1), smooth_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMLj__fjwrnL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI2eWggT14px"
      },
      "source": [
        "### 최종 모델 선정 및 평가\n",
        "\n",
        "학습 커브에서 최적 하이퍼파라미터를 찾았다면, 해당 파라미터로 최적 모델을 학습하고 평가를 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLf-OG041yzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b72750-ee86-411e-fab8-cf28dcafdf63"
      },
      "source": [
        "model = build_model()\n",
        "model.fit(x_train, y_train, epochs=90, batch_size=18, verbose=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "Epoch 2/90\n",
            "Epoch 3/90\n",
            "Epoch 4/90\n",
            "Epoch 5/90\n",
            "Epoch 6/90\n",
            "Epoch 7/90\n",
            "Epoch 8/90\n",
            "Epoch 9/90\n",
            "Epoch 10/90\n",
            "Epoch 11/90\n",
            "Epoch 12/90\n",
            "Epoch 13/90\n",
            "Epoch 14/90\n",
            "Epoch 15/90\n",
            "Epoch 16/90\n",
            "Epoch 17/90\n",
            "Epoch 18/90\n",
            "Epoch 19/90\n",
            "Epoch 20/90\n",
            "Epoch 21/90\n",
            "Epoch 22/90\n",
            "Epoch 23/90\n",
            "Epoch 24/90\n",
            "Epoch 25/90\n",
            "Epoch 26/90\n",
            "Epoch 27/90\n",
            "Epoch 28/90\n",
            "Epoch 29/90\n",
            "Epoch 30/90\n",
            "Epoch 31/90\n",
            "Epoch 32/90\n",
            "Epoch 33/90\n",
            "Epoch 34/90\n",
            "Epoch 35/90\n",
            "Epoch 36/90\n",
            "Epoch 37/90\n",
            "Epoch 38/90\n",
            "Epoch 39/90\n",
            "Epoch 40/90\n",
            "Epoch 41/90\n",
            "Epoch 42/90\n",
            "Epoch 43/90\n",
            "Epoch 44/90\n",
            "Epoch 45/90\n",
            "Epoch 46/90\n",
            "Epoch 47/90\n",
            "Epoch 48/90\n",
            "Epoch 49/90\n",
            "Epoch 50/90\n",
            "Epoch 51/90\n",
            "Epoch 52/90\n",
            "Epoch 53/90\n",
            "Epoch 54/90\n",
            "Epoch 55/90\n",
            "Epoch 56/90\n",
            "Epoch 57/90\n",
            "Epoch 58/90\n",
            "Epoch 59/90\n",
            "Epoch 60/90\n",
            "Epoch 61/90\n",
            "Epoch 62/90\n",
            "Epoch 63/90\n",
            "Epoch 64/90\n",
            "Epoch 65/90\n",
            "Epoch 66/90\n",
            "Epoch 67/90\n",
            "Epoch 68/90\n",
            "Epoch 69/90\n",
            "Epoch 70/90\n",
            "Epoch 71/90\n",
            "Epoch 72/90\n",
            "Epoch 73/90\n",
            "Epoch 74/90\n",
            "Epoch 75/90\n",
            "Epoch 76/90\n",
            "Epoch 77/90\n",
            "Epoch 78/90\n",
            "Epoch 79/90\n",
            "Epoch 80/90\n",
            "Epoch 81/90\n",
            "Epoch 82/90\n",
            "Epoch 83/90\n",
            "Epoch 84/90\n",
            "Epoch 85/90\n",
            "Epoch 86/90\n",
            "Epoch 87/90\n",
            "Epoch 88/90\n",
            "Epoch 89/90\n",
            "Epoch 90/90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63ac30b290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ax0k-vs57gf"
      },
      "source": [
        "시험셋으로 2천달러 이상 차이가 나는 것을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgVv6Ic5kn_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26770a83-2ee3-470d-ff3c-db682bf60a63"
      },
      "source": [
        "x_test -= mean\n",
        "x_test /= std\n",
        "\n",
        "test_mse_score, test_mae_score = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(test_mae_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 16.5456 - mae: 2.5823\n",
            "2.5822856426239014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ceb2EDJk1DY"
      },
      "source": [
        "### 제출용 모델 결과 파일 저장\n",
        "\n",
        "시험셋으로 테스트한 결과를 제출하기 위해 모델 결과 파일을 저장합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO0XN7PkkyPU"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "np.savetxt('y_pred.csv', y_pred, fmt='%f')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}